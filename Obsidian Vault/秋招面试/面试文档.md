---
date: 2025-09-14T20:33:55+08:00
draft: true
title: '未命名'
slug: '20250914-b4e62mdi'
tags:
  - 标签
categories:
  - 分类
---

## 1 自我介绍

面试官您好！我叫廖明秋，来自湖南衡阳，是武汉大学电子信息专业的在读硕士研究生，本科也同样毕业于武汉大学。非常荣幸能有机会参加今天的面试，感谢您的时间。

我主要专注于后端开发，熟练掌握 Go 语言，并具备 C++ 和 Python 的开发能力。在校期间，我对计算机基础知识进行了扎实学习，尤其在分布式系统和云原生领域有深入研究和实践，并积累了丰富的工程经验。我曾在阿里云容器服务部门实习，主要负责 ACK AI 助手的实现与带外数据链路建设。我还独立完成了一个微服务即时通讯项目，深入实践了 Etcd、gRPC、Kafka 等核心组件在微服务架构中的应用。

在个人特质方面，我热爱运动，长期坚持健身，培养了坚韧的毅力和高度的自律性。同时，我积极参与科研竞赛和学校活动，不断提升技术深度与团队协作能力，并乐于通过技术博客分享学习心得与项目经验。

我的优势在于对技术原理的深入探索能力、扎实的工程实践能力，以及强烈的自我驱动和责任感。非常期待能有机会加入贵公司，与优秀的团队共同成长，贡献我的力量。谢谢！

## 2 实习经历

面试官您好！我在阿里云容器服务部门实习期间，主要聚焦于两个核心方向：一是 ACK AI 助手的实现与工程化，二是对带外数据链路的建设。

首先，在 AI 助手方向，我的工作主要体现在三个层面：

1. ACK MCP Server 的实现与优化：
   - 我负责实现了 **ACK MCP Server**，其核心是将 **kubectl、OpenAPI SDK** 以及上下文补充等多种操作方法，统一封装为大模型（LLM）可稳定调用的**结构化 Tools**，并内建了完善的认证授权机制。
   - 为了显著降低模型的调用难度和减少幻觉，我对 API 描述与参数进行了优化，并内置了常用的 Prompt。这个成果最终开源，并提供了 Helm Chart 方便部署，实现了对外的服务能力。
2. Multi-Agent 架构的设计与实现：
   - 我基于 **LangGraph** 框架，设计并实现了一套 **“协调者-专家”分层式智能体架构**。
   - 我们通过 **ReAct（Reasoning and Acting）与 Plan-Execute 模式（并加入了 RePlan 机制）**，使得这套智能体系统既能够高效处理特定领域的复杂问题，也具备了通用任务的规划与执行能力。
3. AI 助手生产级工程化落地：
   - 为了确保 Agent 在生产环境的可用性与健壮性，我实现了多项关键模块，包括**结构化记忆、持久化会话管理、结合知识库的检索增强 (RAG)**，以及支持**人机协作 (HITL)** 的机制。
   - 同时，我也完成了对之前提到的 **MCP Server 的多租户改造**，确保了在多用户场景下的安全隔离与合规操作。

第二个方向是带外数据链路的建设：

- 这件事情的背景是传统的 Kubernetes 集群健康检查机制仅限于集群内部，无法感知来自底层基础设施（如物理硬件故障、宿主机计划性维护）的事件。
- **链路实现：** 我遵循 Kubernetes 的**控制器所有权模式**，构建了一条从底层基础设施到 ACK 集群的事件链路。具体是通过 SLS 订阅并解析来自 ECS 和灵骏等平台底层硬件的事件。
- 我设计了一个自动化流程，将这些原始故障 Event 转化为 Kubernetes 节点上的 **Label**。然后通过实时 **Watch Label 变化**，动态修改节点的 **Condition**，从而驱动 ACK 集群进行相应的自愈操作。
- 这个架构通过**事件驱动**保证了实时性，同时通过**定期同步**实现了最终一致性，极大地增强了系统的鲁棒性与可维护性。

我的最主要成果是成功交付了具备工具调用、知识检索、根因分析和自主修复能力的智能运维助手；同时，通过带外链路建设，我们将节点故障的感知时间从传统的 15 分钟大幅缩短至秒级，显著提升了 ACK 集群的自愈能力和用户体验。

## 3 即时通讯系统

面试官你好，第一个项目是我最近做的一个分布式的微服务即时通讯系统，支持高并发、低延迟和高可用性。

首先，这个系统采用了四层架构，分别是 gateway 网关层、logic 逻辑处理层、task 任务处理层和 repo 数据存储层。不同层次分别处理不同的内容，层级之间使用 etcd 来进行服务发现，使用 gRPC 和kafka进行通信。

gateway 是所有客户端（Web、移动端）的唯一入口点。它处理客户端连接（HTTP/WebSocket），转换协议，并将请求路由到适当的后端服务。它负责管理 WebSocket 连接以实现实时通信。这一层主要是基于 Gin 实现 Web 服务，用于提供用户注册、登录、添加好友等功能，基于 ws 实现长连接，维护用户的在线状态，将 userID - instanceID 映射对通过 logic 写入到缓存中。对收到的消息发送到 kafka 中并从 kafka 中接收到消息/事件（上下线、成员变更、已读回执）等，推送给用户。

logic层对外提供 RPC 服务，内部主要负责接收 API 接入层的用户登录、认证请求。此外，还需要出来来自长连接层的消息推送、状态变更。对于一条消息推送，logic层会将其处理后，为每一个消息通过分布式 ID 算法提交一个唯一的 ID，将其发送到消息队列中。对于普通消息和小群聊消息，直接采用写扩散策略，发送给每个用户的 topic，同时也发送到持久化的 topic 中。如果是大群聊，会将消息发送给 task，task 会对该大群聊消息进行扇出。如果是特别大的群聊，比如有 2000 人，会分成 4份，每份 500，交给 4 个task来进行扇出。此外，长连接层监控到有用户的上线和下线时，会将上线下线消息和对应的房间号发送到逻辑处理层，逻辑处理层通过 rpc 调用 repo 作为缓存，维护每一个房间的在线人数和成员信息，还会维护用户 ID 到长连接层实例 ID 的一个映射关系。

task 层除了实现大群扩散外，还需要负责订阅持久化的消息队列，通过 rpc 将消息持久化到 repo 中。同时，另一个消费者组订阅消息，将其写入到 es 中，用于实现搜索功能。task 还接受搜索请求，返回结果。后续我还打算在这上面实现 AI 助手的功能，例如对群聊天进行摘要、AI 分析聊天添加待办和提醒。

最后是 repo 层，这一层我主要使用的是 mysql和redis，对外通过 rpc 提供服务。这一层用于持久化用户表、会话表、消息表等，对于消息表，采用单表存储全网的聊天数据，在这个表上面我使用 gorm 分表插件，基于 convention-id 作为分表键，实现了分表。因为没有做客户端，每次用户登录需要拉取所有会话的最近100条记录，这部分我采用了 cache-aside 的方式，持久化消息时会同时写入到 redis，使用 zset 基于时间戳来进行排序。此外，还使用 redis 缓存群组、用户的在线情况、连接到哪个 Gateway 实例等。

功能上，本系统支持单聊、群聊、和世界聊天室。因为大部分的人都不太愿意去注册登录，因此我实现这个功能，所有用户包括游客都能在里面聊天，这也是分表的一个热点键，这部分我还没有想好怎么做。同时，实现了消息的大群扇出策略。

为了提高系统的可拓展性和可靠性，采用了 etcd 作为配置中心和服务发现中心，服务启动时只需要基于环境变量注入 etcd 地址，其他配置全部从 etcd 中获取。并且还能够支持热更新。服务启动时，会像 etcd 中请求唯一 instance ID，可以作为 redis 的映射关系，雪花算法的 机器号。启动后会向 etcd 中注册自己作为一个 RPC 服务器，包含服务名，IP和端口，客户端可以监听获取到所有的服务器。此外，还通过 etcd resolver，实现服务发现和负载均衡，客户端不需要手动处理多个后端地址，会给客户端提供一个抽象的连接，这个连接底部维护了一个连接池，可以动态伸缩。

此外，我还实现了限流组件、幂等组件、熔断组件等，基于幂等组件+雪花ID 的有序性，确保消息不重不漏，消息有序。熔断组件保证上游的错误不会导致下游出错，避免随机指数退避的重试占用太多资源。限流组件限制 RPC 的和 http 请求的速率，避免压力过大。

通过这样的分层设计和技术选型，我们的系统能够支持 **5W+ 的每秒查询率 (QPS)**，并保证消息投递延迟稳定在 **50 毫秒** 以内，同时具备秒级的故障恢复能力，能够高效地满足大规模用户的实时通讯需求。

好的，面试官。

我已经完成了您交办的任务。基于您提供的项目信息和相关文档，我为您准备了一套完整的、用于技术面试的沟通方案。这套方案旨在帮助您专业、严谨、且有深度地展示您的 GoChat 项目。

现在，我将最终的完整方案提交给您审阅。

---

### 3.1 **最终方案：GoChat 项目面试沟通材料**

#### 3.1.1 **第一部分：优化后的项目介绍文稿**

**(此部分用于您在面试时，主动、系统地介绍您的项目)**

> 面试官你好，我介绍一下我最近负责的 GoChat 项目。这是一个基于 Go 语言构建的、支持高并发与高可用的分布式即时通讯系统。
> 
> 项目的设计目标是构建一个具备**低延迟消息投递**、**高可靠性**及**良好水平扩展能力**的实时通讯平台。在压测中，系统能够稳定支持超过 **5W 的 QPS**，并将核心消息的 P99 延迟控制在 **100ms** 以内。
> 
> **1. 系统架构设计**
> 
> 为了实现上述目标，我将系统设计为经典的四层微服务架构，各层职责清晰、独立部署和伸缩。
> 
> * **Gateway (网关层)**: 作为所有客户端的统一入口，负责管理海量的 WebSocket 长连接，处理 HTTP 请求，并将上行消息路由到 Kafka。
> * **Logic (逻辑层)**: 这是系统的业务处理核心。它负责用户认证、会话管理，并根据不同的业务场景（如单聊、群聊）制定消息的分发策略。
> * **Task (任务层)**: 这是一个异步任务处理中心。所有非核心链路上的耗时操作，如大群消息的扇出、消息的持久化、以及将消息同步到 Elasticsearch 进行索引，都由该层处理。这种设计极大地保障了核心收发链路的低延迟和高吞吐。
> * **Repo (数据层)**: 这是一个统一的数据访问抽象层。它通过 gRPC 接口，为上层服务提供了对底层 MySQL 和 Redis 的结构化访问，屏蔽了存储细节，并实现了高效的数据读写。
> 
> 在服务间协作方面，我们采用 **gRPC** 进行高性能的同步RPC调用，同时以 **Kafka** 作为消息总线，驱动服务间的异步通信和解耦。服务的注册与发现基于 **etcd** 实现，并且我们利用 etcd 构建了 gRPC 的客户端 Resolver，实现了动态的服务发现和负载均衡。
> 
> **2. 核心数据流**
> 
> 系统的核心数据流遵循一个关键原则：**“持久化先行，推送解耦”**，以此确保消息的最终一致性和可靠性。
> 
> 1. **消息上行与预处理**: 客户端消息通过 WebSocket 发送到 `Gateway`，`Gateway` 将其投递至 Kafka 的 `upstream` 主题。`Logic` 层消费此消息后，会立即为其分配一个全局唯一的、趋势递增的 **Snowflake ID**，并进行权限校验。
> 
> 2. **持久化与推送分离**:
>    
>    * **持久化**: `Logic` 层会立刻将带有唯一 ID 的消息转发到 `gochat.messages.persist` 主题。`Task` 服务会异步消费该消息，并调用 `Repo` 服务完成**唯一一次**的数据库持久化。
>    * **分发策略**: 与此同时，`Logic` 层会根据会话类型执行不同的分发策略：
>      * 对于**单聊或小群**，采用**写扩散**策略。`Logic` 直接查询在线关系，并将消息投递到目标 `Gateway` 实例的专属 `downstream` 主题中，实现快速推送。
>      * 对于**超大群聊**，则采用**读扩散**（或称异步扇出）策略。`Logic` 仅将一个轻量级的扇出任务投递到 Kafka 的 `fanout` 主题，交由多个 `Task` 服务实例并发处理，将单次大群扩散的压力均摊，避免阻塞 `Logic` 层的核心线程。
> 
> **3. 技术难点与解决方案**
> 
> 在项目实践中，我们解决了一些关键的技术挑战，其中最具代表性的是以下几点：
> 
> **第一，在架构层面，我们构建了一个高度复用且健壮的 `im-infra` 基础设施库。**
> 这不仅仅是一个工具包，而是一套遵循统一设计哲学（如 Provider 模式、函数式选项依赖注入）的生产级解决方案。它包含了：
> 
> * **`coord` 组件**: 基于 etcd 封装了服务发现、配置中心和分布式锁，并支持配置的动态热更新。
> * **`once` + `uid` 组件**: 通过幂等性组件和分布式ID生成器的结合，从机制上保证了消息在分布式环境下的“不重不漏”和“精确一次处理”。
> * **`breaker` 和 `ratelimit` 组件**: 我们实现了动态配置的熔断器和分布式限流器，以应对下游服务故障和上游流量冲击，确保了系统整体的高可用性。
> 
> **第二，在数据存储层面，我们针对 IM 场景的特点进行了深度优化。**
> 
> * **消息分表**: 为了应对高并发写入，我们基于 `conversation-id` 对核心的消息表进行了水平分片，将压力分散到不同的物理表中。
> * **缓存设计**: 我们全面采用了 `Cache-Aside` 模式。例如，用户的在线状态、会话列表等高频读取数据都存储在 Redis 中。特别是对于“拉取最近消息”这一场景，我们利用 Redis 的 `ZSET` 数据结构，按消息时间戳排序，实现了高效的范围查询，极大降低了数据库的读取压力。
> * **热点问题思考**: 我们也意识到了“世界频道”这类超大公共群聊可能导致的分片热点问题。对此，我们未来的规划是采用单独的物理表，或在必要时引入 TiDB 这类具备良好扩展性的 NewSQL 数据库来解决。
> 
> **4. 总结**
> 
> 通过上述的分层架构、消息驱动模式以及一系列针对性的优化，GoChat 系统在保证功能完备的同时，也实现了高性能和高可用的设计目标。
> 
> 以上是我的项目介绍，谢谢。

---

#### 3.1.2 **第二部分：核心技术难点深入问答 - 准备腹稿**

**(此部分用于您在介绍完毕后，应对面试官可能发起的深度追问)**

**1. 追问点：`im-infra` 基础设施库的设计哲学**

* **面试官可能问：** “你提到你构建了一个独立的 `im-infra` 库，这非常有趣。能详细谈谈你为什么要做这样的设计吗？它的核心设计思想是什么？”
* **您的回答思路：**
  * **动机**: 避免在多个微服务中重复造轮子，解决代码重复、版本不一、行为不一致的问题，降低维护成本。核心目标是**提供标准化的、生产级的、即插即用的基础组件**。
  * **核心设计思想**:
    * **统一的 `Provider` 模式**: 通过 `New(ctx, config, …opts)` 标准签名，清晰化组件的静态配置和外部依赖注入，提升可测试性。
    * **声明式的动态配置**: 组件通过 `coord` 组件**自治地**监听 `etcd` 中的配置变更并热更新，保证了配置的“唯一真实来源”。
    * **环境感知的默认配置**: `GetDefaultConfig(env)` 函数大大降低了新服务的接入成本。
  * **优势**: 总结为**高度复用与一致性**、**关注点分离**、**提升系统健壮性**。

**2. 追问点：消息的“精确一次处理” (Exactly-Once) 是如何实现的？**

* **面试官可能问：** “你提到确保了消息的精确一次处理。能具体解释一下这个流程吗？比如，当 `logic` 服务处理完一条消息后突然宕机，如何保证不重复处理？”
* **您的回答思路：**
  * **定义问题**: 阐明分布式系统中，由于网络、重启等原因导致的重复消费问题。
  * **解决方案**: 核心是**在消费端实现业务逻辑的幂等执行**。
    1. **全局唯一 ID**: `Logic` 层消费消息时，从 `uid` 组件获取 `Snowflake ID` 作为 `message_id`。
    2. **幂等键**: 使用 `message_id` 作为幂等操作的唯一标识。
    3. **`once.Do` 操作**: 在执行核心业务逻辑前，调用 `onceProvider.Do(ctx, message_id, …)`。
    4. **内部机制**: `once` 组件利用 Redis 的 `SETNX` 保证只有第一次请求能成功设置幂等键并执行业务逻辑。后续的重复请求会因为键已存在而直接返回成功，但跳过业务逻辑的执行。
  * **应对宕机**: 即使服务在 `commit offset` 前宕机，重启后再次消费，`once` 组件也会因为 Redis 中已存在的幂等键而阻止业务逻辑的重复执行。

**3. 追问点：大群消息扇出 (Fan-out) 的具体设计**

* **面试官可能问：** “对于大群消息，你提到了异步扇出的策略。能详细说明一下这个过程吗？如何保证不漏掉任何一个用户？”
* **您的回答思路：**
  * **问题背景**: 同步处理大群扇出会严重阻塞 `Logic` 服务的核心链路。
  * **详细流程（二级分发）**:
    1. **`Logic` 层**: 识别为大群消息后，仅投递一个轻量级的“扇出任务”（含 `conversation_id`, `message_id`）到 Kafka 的 `fanout` 主题。
    2. **`Task` 层（第一次分发）**: 单个 `Task` 实例消费该任务，获取群全量成员列表，在内存中切分成多个子任务分片（如每 500 人一片）。
    3. **`Task` 层（第二次分发）**: 将这些带有具体成员列表的子任务，再次投递到 Kafka 的 `fanout.execute` 主题。
    4. **`Task` 层（最终执行）**: `Task` 集群中的多个实例并发地消费 `execute` 主题中的分片任务，执行最终的在线状态查询和消息推送。
  * **优势与可靠性**: 这种设计实现了任务的分解与并行处理，充分利用了集群的水平扩展能力。同时，依赖 Kafka 的 `at-least-once` 投递语义和消费端的幂等性设计，确保了消息分发的高效与可靠。

---

好的，面试官。很高兴您对我们的可观测性建设感兴趣。这确实是我们项目工程化实践中非常核心的一环。

如果面试官问我：“你的 `metrics` 是怎么做的呢？” 我会这样来讲解：

---

### 3.2 **GoChat 可观测性 (`metrics`) 组件讲解**

“好的，面试官。关于我们系统的可观测性，我们构建了一个统一的 `metrics` 组件，它是我们 `im-infra` 基础设施库的核心成员之一。这个组件的目标是为所有微服务提供**开箱即用的、自动化的、遵循业界标准的 Metrics（指标）和 Tracing（链路追踪）能力**。”

“我们的核心设计理念是**自动化与零侵入**。我们希望业务开发者在不修改或极少修改业务代码的情况下，就能自动获得覆盖所有请求的、丰富的可观测性数据。”

“为了实现这个目标，我们的 `metrics` 组件主要做了以下几件事情：”

**第一：基于 OpenTelemetry 标准构建，实现技术栈解耦。**

“我们没有自造轮子，而是选择了业界事实标准 **OpenTelemetry** 作为底层框架。这样做最大的好处是**技术栈解耦**。我们的 `metrics` 组件负责在服务内部生成符合 OpenTelemetry 规范的数据，然后可以通过配置，将这些数据无缝地导出到任何兼容的后端系统，比如用 **Jaeger** 进行链路追踪，用 **Prometheus** 收集和展示指标。未来如果想切换到其他监控系统，我们只需要修改配置，而不需要改动任何一行业务代码。”

**第二：通过拦截器（Interceptor）和中间件（Middleware）实现自动化数据采集。**

“这是我们实现‘零侵入’的关键。我们的 `metrics` 组件对外暴露了三个核心方法：”

* `GRPCServerInterceptor()`
* `GRPCClientInterceptor()`
* `HTTPMiddleware()`

“开发者在初始化服务时，只需要将这些拦截器/中间件“挂”在 gRPC 服务器或者 Gin HTTP 引擎上。之后，**所有流经的请求，无论是入站还是出站，都会被自动包裹**。拦截器会自动完成以下所有工作：”

1. **创建或延续 Trace**：检查请求头中是否有上游的 Trace Context，有则延续，无则创建一个新的 Trace。
2. **记录标准指标**：自动记录请求的**延迟（Latency）、计数（Count）和错误率（Error Rate）**。这些指标都会带上丰富的标签（Labels），比如 gRPC 的方法名、HTTP 的路径、状态码等，方便在 Prometheus 中进行多维度聚合和分析。
3. **注入 Trace Context**: 在发起出站请求（如 gRPC client call）时，自动将当前的 Trace ID 注入到请求头中，从而将跨服务的调用链串联起来。

“通过这种方式，业务开发者完全不需要关心可观测性的实现细节，只需要进行一次性的初始化集成，就能获得覆盖全链路的追踪和监控能力。”

**第三：提供简洁的 API 用于自定义业务指标。**

“除了自动采集的技术指标，我们也需要监控关键的业务指标，比如‘用户登录成功次数’或‘发送的消息大小’。为此，`metrics` 组件提供了非常简洁的辅助函数：”

* `NewCounter(name, description)`: 用于创建一个**计数器**，比如 `login_success_total`。
* `NewHistogram(name, description, unit)`: 用于创建一个**直方图**，非常适合记录像请求延迟、消息大小这类需要观察分布情况的数据。

“业务代码只需要在初始化时创建一次这些指标，然后在适当的业务逻辑位置调用 `counter.Inc()` 或 `histogram.Record()` 即可。这些自定义指标同样会被 Prometheus 自动采集。”

**第四：深度集成的结构化日志。**

“我们认为，可观测性的三大支柱——Metrics, Tracing, Logging——应该协同工作。因此，我们的 `metrics` 组件与 `clog` 日志库进行了深度集成。在拦截器自动生成的日志中，会**自动包含当前的 `trace_id` 和 `span_id`**。当我们在 Jaeger 中发现一个慢请求时，可以直接复制其 `trace_id`，然后到 Loki（我们的日志系统）中搜索，就能立即筛选出与这次慢请求相关的所有服务的、全部的详细日志。这极大地提升了我们线上排障的效率。”

**总结一下：**

“所以，当您问我们的 `metrics` 是怎么做的时候，总结来说就是：我们基于 **OpenTelemetry** 标准，构建了一个**以自动化拦截器为核心**的统一可观测性组件。它不仅能自动采集所有请求的技术指标和链路信息，还提供了简单的 API 用于自定义业务指标，并与我们的结构化日志系统深度集成，最终为整个分布式系统打造了一个强大、易用且低侵入的“神经中枢网络”，使我们能够清晰地观测到系统内部发生的一切。”

“**Gauge (仪表盘)** 是一种可以任意上升和下降的瞬时值指标。如果说 Counter 是记录‘发生了多少次’，那么 Gauge 就是记录‘现在是多少’。”

“它非常适合用来监控那些动态变化的、代表系统某个时间点状态的数值。在我们的 GoChat 项目中，典型的应用场景包括：”

- **监控当前在线用户数**: `im-gateway` 服务会定期上报当前持有的 WebSocket 连接数，这就是一个 Gauge 指标，比如 `gochat_gateway_active_connections`。
- **监控队列积压情况**: `im-task` 或 `im-logic` 中的消费者可以定期上报 Kafka 消费组的 `lag`（积压消息数），帮助我们判断消费能力是否出现瓶颈。
- **监控资源使用率**: 比如 Goroutine 的数量、内存中的缓存对象数量等。

“和 Counter、Histogram 一样，我们也为 Gauge 提供了简洁的创建和更新 API。业务代码可以在初始化时创建一个 Gauge，然后在需要更新状态时调用 `gauge.Set(value)` 方法来上报最新的瞬时值。”

“所以，总结一下我们支持的自定义指标：”

1. **Counter (计数器)**: 只增不减，用于记录累积事件，如总请求数、总错误数。
2. **Histogram (直方图)**: 用于记录数值的分布情况，如请求延迟、消息大小。
3. **Gauge (仪表盘)**: 可增可减，用于记录瞬时状态值，如当前在线人数、队列长度。

“通过这三种核心指标类型的组合，我们就能全面地、多维度地度量系统的技术指标和业务指标，为系统的监控、告警和容量规划提供了坚实的数据基础。