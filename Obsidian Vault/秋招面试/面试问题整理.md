---

date: 2025-09-18T10:41:53+08:00
draft: true
title: '未命名'
slug: '20250918-4s96szhr'
tags:
  - 标签
categories:
  - 分类
---

## 1 数据库断电重启与恢复机制

### 1.1 正常重启过程

- **优雅关闭**：停止接受新连接，等待当前事务完成，温和断开空闲连接
- **数据刷盘**：将内存中的脏页、预写日志（WAL）等所有缓存数据强制刷写到磁盘
- **清理工作**：释放数据库文件锁，清理资源后正常退出进程
- **快速启动**：检测到干净关闭状态，无需恢复操作，启动速度快

### 1.2 断电重启影响

- **进程被强制终止**：所有内存中未刷盘的缓存数据全部丢失
- **磁盘数据状态不确定**：
  - 可能存在已提交但未刷盘的事务
  - 可能存在未提交的事务部分修改
  - 文件系统层面可能出现写了一半的文件损坏

### 1.3 崩溃恢复机制

- **检测异常关闭**：通过锁文件或状态文件识别非正常关闭状态
- **读取预写日志**：从最后一个检查点开始读取 WAL/Redo Log
- **前滚恢复**：重放所有已提交事务的修改，确保数据不丢失
- **回滚未提交事务**：撤销断电时未完成事务的修改，保证数据一致性

### 1.4 关键概念

- **WAL（预写日志）**：数据持久性的实现原则
- **Redo Log**：WAL 原则的具体实现方式
- **检查点**：数据库定期将内存数据同步到磁盘的机制，用于优化恢复过程

现代数据库通过预写日志和崩溃恢复机制，确保即使在意外断电情况下也能保持数据的完整性和一致性。

## 2 Go 最新特性

### 2.1 容器感知 & 动态调整的 GOMAXPROCS

**核心变化**  
- 默认值不再仅仅是启动时的逻辑 CPU 数，而会：
  1. 在 Linux 中受 cgroup CPU 带宽限制影响（更贴近 Kubernetes "CPU limit" 配置）。
  2. 运行期动态感知 CPU 数或配额变化并调整（弹性扩缩容时更合理）。

**价值**  
- 避免在受限容器中因为过高的 GOMAXPROCS 造成调度开销和无效抢占。
- 容器配额热变更后（某些平台支持）无需重启即可适配。

### 2.2 实验性 GC：greenteagc（`GOEXPERIMENT=greenteagc`）

**目标**  
- 改善小对象标记/扫描局部性与多核扩展性。
- 预期 GC 开销降低 10–40%（针对 "GC 压力型 " 服务：大量短生命对象 / 高频分配）。

**启用**
- 构建时：`GOEXPERIMENT=greenteagc go build ./…`
- 与现有调参（如 `GOGC`）兼容。

### 2.3 新 JSON 实现（`jsonv2` 实验）

**痛点缓解**  
- 现有 `encoding/json` 在解码性能、错误信息控制、可扩展配置方面长期受限。
- 新实现解码性能显著提升（尤其是大批量 & 深层结构）。

**启用方式**  
- 构建：`GOEXPERIMENT=jsonv2 go build`
- 两个新包：  
  - 高层 API：`encoding/json/v2`  
  - 低层语法流处理：`encoding/json/jsontext`
- 同时旧 `encoding/json` 在实验开启时底层会自动使用新引擎（逻辑行为尽量兼容）。

### 2.4 并发测试虚拟时间：`testing/synctest`

**解决的问题**  
- 传统测试使用 `time.Sleep`、或 race- 易感的轮询等待，导致：不稳定、慢、偶现失败。
- `synctest.Test` 建立 " 气泡环境 "：  
  - 时间虚拟：所有 `time.*` 基于伪时钟  
  - 当所有 goroutine 阻塞，时钟自动快进到下一事件点 —— 消除硬等待。

**典型用法示例（概念化）**  

````go
synctest.Test(t, func(t *synctest.T) {
    go func() {
        timer := time.NewTimer(5 * time.Second) // 伪时间
        <-timer.C
        close(ch)
    }()
    t.Wait() // 等待直到当前气泡内 goroutine 全部阻塞（钟前进）
    // 这里已经逻辑上“经过”5s，无真实耗时
})
````

### 2.5 Swiss Table，新 Map 实现（1.24）

Go 1.24 把内置 `map` 的底层实现换成类似 Swiss Table（借鉴 Abseil/Goog. hash map）的**紧凑开放寻址 + 控制字节分组探测**结构，替换之前的 " 溢出桶链表 " 方案，带来更高缓存局部性、更少指针、更低 GC 压力与 2–3%（全局基准平均）的 CPU 减少（热点 map 更明显）。

| 维度      | 旧：链式桶（bucket + overflow） | 新：Swiss 风格（控制字节 + 扁平化）                   | 影响                 |
| ------- | ------------------------ | ---------------------------------------- | ------------------ |
| 存储模式    | 定长桶 + 溢出指针链              | 连续数组分组，减少或延后溢出结构                         | 更少指针追踪，cache 命中率 ↑ |
| 探测策略    | 初始桶 + 链扫描                | 受控（控制字节 + SIMD/批量比较）线性/二次式局部探测           | 查找更少分支和跳转          |
| 装载因子    | 实际使用中为避免 overflow 容易提前扩容 | 允许接近高装载（例如 alpha≈0.85–0.9alpha≈0.85–0.9） | 占用内存更紧凑            |
| 删除标记    | 特殊标记 + 可能保留空槽            | 控制字节里表示 " 已删除 "/" 空 "                    | 更快再利用，降低碎片         |
| GC Root | 每个桶含指针区 + 溢出链            | 指针集中，溢出少                                 | GC 标记成本下降          |
| 失败路径    | 长溢出链退化                   | 探测序列受限，坏 hash 仍可能变慢                      | 哈希质量更重要            |
| 迭代顺序    | 未定义（散列 + 桶链遍历）           | 仍未定义（实现可变）                               | 不可依赖任何顺序假设         |

## 3 LRU-K 算法（一般取 2）

传统的 LRU（最近最少使用）算法只关注 " 最近一次访问时间 "。它很容易被**一次性的全表扫描或大量随机访问**（Scan Operations）所 " 污染 "。这些数据被访问一次后就会挤掉热点数据，导致缓存命中率急剧下降。

LRU-K 的核心思想是**将 " 访问次数 " 和 " 访问时间 " 结合起来**判断数据的热度。它认为，被访问过至少 **K** 次的数据才是真正的热点数据。

LRU-K 通常维护两个队列：

- **历史队列（或访问记录队列）**：
    - **存储对象**：所有被访问过但总访问次数 **< K** 的数据页。
    - **排序依据**：按照**第一次访问的时间**排序（FIFO）。这个队列不承担缓存功能，只负责记录访问历史。
    - **目的**：过滤掉那些偶尔被访问一次的数据（比如全表扫描），防止它们污染主缓存。
- **缓存队列（主队列，通常是 LRU）**：
    - **存储对象**：所有被访问过至少 **K** 次的数据页，即真正的热点数据。
    - **排序依据**：传统的 **LRU**，即按照**最近访问时间**排序。
    - **目的**：存放真正的热点数据，承担主要的缓存功能。

**4. 访问过程：**

- 当一个数据页被访问时，系统首先检查其访问历史。
- **如果这是它的第 1 次到 (K-1) 次访问**：它会被放入或移动到**历史队列**的头部（按第一次访问时间排序）。此时它不会被缓存。
- **当它的访问次数达到 K 次**：它会被**晋升（Promote）** 到**缓存队列**的头部（成为最新访问的数据）。
- **当它在缓存队列中再次被访问**：它会像传统 LRU 一样被移动到缓存队列的头部。
- **淘汰过程**：
    - 当需要淘汰数据时，**优先淘汰历史队列尾部**的数据（那些只被访问过很少几次，且最早被访问的数据）。
    - 如果历史队列为空，则再去**淘汰缓存队列（LRU 队列）尾部**的数据（真正的热点数据中最不活跃的那个）。

### 3.1 **K 值过小（例如 K=1）**

- **行为**：K=1 时，只要访问一次就能进入缓存队列。这**退化成了传统的 LRU 算法**。
- **问题**：失去了对 " 扫描波 " 的抵抗能力。任何一次性的全表扫描都会瞬间挤掉大量热点数据，导致缓存污染，命中率下降。

### 3.2 **K 值过大（例如 K=5, 10）**

- **行为**：数据需要被访问很多次才会被认可为热点数据，进入缓存。
- **优点**：对 " 扫描波 " 的抵抗能力非常强，只有被反复访问的 " 绝对热点 " 数据才能留在缓存中。
- **缺点**：
    1. **预热慢**：系统启动或新业务上线时，需要较长时间才能让热点数据积累够足够的访问次数，进入缓存。在这段预热期内，性能较差。
    2. **灵活性差**：可能会 " 错杀 " 一些新兴的热点数据（比如突然爆火的商品页面），因为它们需要多次访问才能 " 转正 "，在这个过程中可能会因为内存不足而被淘汰掉。
    3. **开销大**：需要记录每个数据页的访问次数，K 值越大，需要维护的历史信息就越多，算法本身的开销也越大。

## 4 火山模型

火山模型，也称为 **迭代器模型（Iterator Model）**，是数据库系统中最传统和最常见的一种查询执行引擎的实现方式。它的核心思想是：**将每个物理操作符（如 Join、Sort、Scan 等）抽象成一个迭代器（Iterator）**。

每个迭代器都实现三个标准的接口方法：

1. **`Open()`**：初始化操作符的状态，分配必要的资源。例如，打开一个表文件，或为排序申请内存。
2. **`Next()`**：这是最核心的方法。它被调用时，**返回一条符合条件的"下一行"数据（Tuple）**。如果已经没有更多数据了，就返回一个结束标志（EOF）。
3. **`Close()`**：清理操作符的状态，释放资源。例如，关闭文件，释放内存。

### 4.1 执行过程：一个"拉"取数据的过程

查询计划的执行是一棵由这些迭代器组成的树（操作符树）。执行总是从根节点（通常是最终结果集的输出操作符）开始。

- 根节点的 `Next()` 方法被调用。
- 为了生成一条结果，根节点会去调用其子节点的 `Next()` 方法，获取所需的输入数据。
- 子节点为了满足父节点的请求，又会去调用它自己的子节点的 `Next()` 方法。
- 这个过程会一直递归下去，直到调用到叶子节点（通常是表扫描 `Scan` 操作符）。叶子节点的 `Next()` 方法会真正地从磁盘或缓冲池中读取一条数据，并返回给父节点。
- 数据就像火山喷发一样，从底层的叶子节点"冒"到顶层的根节点。因此得名"火山模型"。

### 4.2 火山模型的优点

1. **清晰与模块化（Simplicity & Modularity）**
    - 每个操作符都是一个独立的模块，只通过标准的 `Next()` 接口与上下交互。这使得系统设计非常清晰，易于实现、理解和维护。添加新的操作符很容易。
2. **灵活的流水线（Pipelining）**
    - 由于是基于 `Next()` 一条条记录处理的，**数据可以在操作符之间"流式"传递**。一个操作符在产出第一条结果后，就可以立刻交给父操作符处理，而无需等待整个操作完成。
    - 这大大减少了对中间结果的存储需求，降低了内存压力。例如，`Filter` 和 `Projection` 可以完美地形成流水线。
3. **天然的惰性求值（Lazy Evaluation）**
    - 查询并不是一开始就处理所有数据。只有最顶层的 `Next()` 被调用时，整个执行引擎才会开始工作。这与客户端"需要一条取一条"的需求完美匹配，非常适合交互式场景。

### 4.3 火山模型的缺点

1. **CPU 效率低（高 CPU Cost）**
    - 这是它最核心的缺点。**虚函数调用（Virtual Function Call）开销巨大**。每处理一条数据，都需要调用多次 `Next()` 方法（调用次数 ≈ 操作符树的深度）。在复杂的多表连接查询中，这个深度可能很大。大量的函数调用破坏了 CPU 缓存和分支预测，导致效率低下。
    - 现代 CPU 的瓶颈往往是 CPU 周期而非 I/O，因此这种开销变得不可接受。
2. **不利于向量化优化（Poor for Vectorization）**
    - `Next()` 接口每次只返回一条记录。这使得数据库难以利用现代 CPU 的 **SIMD** 指令集来一次性处理一批数据（向量化执行），从而无法充分发挥硬件性能。
3. **对某些操作不友好（Not All Operations Pipeline Well）**
    - 虽然流水线很好，但有些操作**必须物化（Materialize）整个输入**才能进行。例如 `Hash Join` 的构建阶段、`Sort`、`Group By` 等。在这些操作符处，流水线会中断，需要先将所有数据收集起来，破坏了流式处理的优势。

> [!NOTE] 向量模型
> - **向量化/批处理模型（Vectorized/Batch Model）**：每个 `Next()` 返回一批数据，而不是一条，极大地减少了函数调用开销，并可以利用 SIMD 指令。

## 5 B+ 树实现的优化策略

"我实现了一个基于乐观锁和螃蟹锁的 B+ 树并发控制方案。

**其核心思想是**：先乐观假设操作不影响结构，仅锁叶子节点以求最高效率；若失败则退回到安全的螃蟹锁协议，并通过及时释放'安全'的祖先锁来减少争用。

**这是一个工业级的成熟方案**。为了进一步提升其在高压下的性能，我还考虑了以下几个优化点：

1. **引入读锁与锁升级**：在螃蟹锁遍历阶段先加共享读锁，仅在必要时升级为写锁，极大提升读并发。
2. **预防活锁**：为重试机制添加随机退让（Backoff）策略，避免多个写操作无限冲突。
3. **更细粒度的安全点释放**：在向下过程中，一旦确认某个祖先绝对安全就立即释放其锁，而不是等到最底层。
4. **优化删除路径**：优先选择重新分配而非合并，重新分配可以不用修改父节点，以减少结构变化的传播。"

## 6 可观测性

可观测性体系可以分为三个核心部分：**指标（Metrics）**、**日志（Logs）** 和**追踪（Traces）**。

### 6.1 指标

1. **核心技术**：我们基于 **OpenTelemetry** 标准库，封装了一个名为 `metrics` 的内部基础设施组件。
2. **自动化采集**：
    - 对于 **HTTP 服务 (Gin)**，我们实现了一个**中间件** (`HTTPMiddleware`)。
    - 对于 **gRPC 服务**，我们实现了**服务端和客户端的拦截器** (`GRPCServerInterceptor` 和 `GRPCClientInterceptor`)。
    - **作用**：这些组件能**自动**为每一个请求采集关键性能指标（PMI），比如：
        - **请求速率** (Request Rate)
        - **错误率** (Error Rate)
        - **请求耗时** (Latency)，通常以直方图形式记录，便于计算 P95/P99 等分位数。
3. **自定义业务指标**：除了自动采集，`metrics` 组件还暴露了标准的 `NewCounter` 和 `NewHistogram` 接口。业务代码可以方便地创建自定义指标，例如：
    - `user_logins_total`：用**计数器 (Counter)** 记录用户登录总次数。
    - `message_size_bytes`：用**直方图 (Histogram)** 统计消息体的大小分布。
4. **数据暴露与采集**：
    - 所有指标（自动采集的和自定义的）都通过一个标准的 HTTP 接口（例如 `:9090/metrics`）以 **Prometheus 格式**暴露出来。
    - **Prometheus** 服务器会定期从这个接口**拉取（pull）** 指标数据并存储。这里澄清一下，我们没有使用 Exporter 推送模式，而是 Prometheus 主动拉取，这更符合 Prometheus 的标准工作方式。

### 6.2 日志

1. **核心技术**：我们基于 `uber-go/zap` 封装了一个高性能的结构化日志库 `clog`。
2. **与链路追踪的结合**：这是我们系统的一大亮点。
    - `clog` 库提供了 `WithContext(ctx)` 方法。在业务代码中调用它时，它能**自动从 `context` 中提取出当前的 `trace_id`**，并将其作为日志的一个标准字段打印出来。
    - **效果**：我们所有的日志都自动带上了 `trace_id`。当排查问题时，我们可以在 Grafana (Loki) 中根据一个 `trace_id` 筛选出单次请求在所有服务中打印的全部日志，极大地提高了排障效率。
3. **日志采集与查询**：
    - 应用程序将结构化日志（JSON 格式）输出到标准输出或文件。
    - **Promtail** 作为日志采集客户端，负责收集这些日志并打上标签（如服务名、实例 IP 等）。
    - **Loki** 负责存储和索引这些日志。
    - 最终，我们在 **Grafana** 中通过 LogQL 查询语言，结合 `trace_id` 进行快速的日志检索和分析。

### 6.3 追踪

对于 gRPC 这种同步请求响应模型，我利用了 gRPC 的元数据（Metadata）机制来传递。发送方和接收方拦截器来实现。

对于 Kafka 这种异步消息队列，协议本身没有 Metadata 的概念，但我利用了 Kafka 消息的 Header 来模拟这一机制。

最后，我们将这三大支柱的数据汇集在 **Grafana** 中，形成一个统一的可观测性平台：

- 我们创建了 Dashboard，将 **Prometheus** 的核心指标（延迟、QPS、错误率）以图表形式展示。
- 在同一个 Dashboard 中，我们嵌入了 **Loki** 的日志查询面板，可以根据变量（如 `trace_id`）动态筛选日志。
- Grafana 还支持跳转到 **Jaeger**，让我们能从一个慢请求的指标图表，直接钻取（drill down）到对应的分布式链路详情。

**通过这套体系，我们实现了从宏观监控（Metrics）到分布式调用链（Tracing），再到微观代码事件（Logging）的全方位、立体化的监控，能够主动发现问题、快速定位问题并深入分析根源。**

## 7 高并发系统

- **宏观上**，我关注**架构**，通过**负载均衡、服务拆分、缓存、异步消息队列**来搭建一个可水平扩展的、有弹性的分布式系统。
- **微观上**，我关注**代码**，通过**池化技术、零拷贝、锁优化、高效序列化**来极致化单机性能。

CDN、LB、限流、水平扩展、服务拆分、缓存（多级缓存）、异步化、数据库（读写分离、主从集群结构、分库分表、SQL 索引优化）

线程库、内存池库、零拷贝技术、锁优化（读写锁、无锁设计）、序列化与编码、JVM 运行时优化。

## 8 Ws 心跳机制

### 8.1 TCP Keep-alive (传输层心跳)

- **传输层**。这是操作系统内核实现的 TCP 协议栈的一部分。
- 它的**唯一目的**是检测一个 TCP 连接是否**还活着**。它不关心你的应用逻辑，只关心对方的主机是否还能在网络层面做出响应。
- 原理：在一个连接空闲（无数据交换）超过一段时间后（通常默认是 **2 小时**！），操作系统会向对端发送一个 TCP keep-alive 探测包。如果对方正常，会回复一个 ACK；如果多次重试后都失败，操作系统就会认为这个连接已经断开，并关闭它。
- **无法感知应用层状态**：即使 TCP 连接是通的，玩家的游戏客户端应用可能已经崩溃、卡死、或者手机 APP 被切换到后台。TCP 对此一无所知，因为它**探测的是网络层的主机**，而不是应用层的进程。

### 8.2 WebSocket Ping/Pong (应用协议层心跳)

- **应用层**。但它是 WebSocket **协议本身**定义的一个控制帧（Control Frame），属于 WS 协议规范的一部分。
- WebSocket 协议在设计时就提供了 Ping 和 Pong 帧，用于**心跳和保活**。一方（通常是服务器）可以发送一个 Ping 帧，另一方必须在合理时间内回复一个 Pong 帧。
- 它的目的比 TCP keep-alive 更进了一步：它不仅检查网络连接是否存活，还**隐式地**检查了对端的 WebSocket 协议实现是否还在正常工作。
- **浏览器实现的不确定性**：虽然 WebSocket 协议规定了 Ping/Pong，但 **Web API（浏览器中的 `WebSocket` 对象）并没有向 JavaScript 开发者暴露发送 Ping 或接收 Pong 的接口**。在浏览器环境中，只有浏览器本身能处理 Ping/Pong 帧，并自动回复 Pong。服务器可以发 Ping 给浏览器，浏览器会自动回 Pong，但浏览器无法主动发 Ping 给服务器。这导致了**不对称性**，服务器无法依赖客户端发来的 Ping 包。
- **缺乏业务逻辑**：它仍然是一个相对底层的机制。Pong 帧的回复是浏览器/底层库自动完成的，即使你的游戏客户端逻辑已经卡死（比如 JavaScript 陷入死循环），但只要 WebSocket 连接本身没断，浏览器仍然会自动回复 Pong。服务器无法得知客户端游戏逻辑的实际健康状态。

**小结：WebSocket Ping/Pong 是很好的保活机制，尤其对于服务器主动探测浏览器客户端。但由于浏览器 API 的限制和缺乏业务状态感知，它仍然不够全面。**

### 8.3 应用层心跳 (业务层心跳)

- **纯应用层/业务层**。这是游戏开发者**自己设计和实现**的、通过 WebSocket 连接发送的**普通数据消息**。它通常是一个简单的 JSON 或二进制协议包，比如 `{“cmd”: “heartbeat”, “client_time”: 12345678}`。
- **完全可控**：心跳间隔完全由你决定。对于快节奏的射击游戏（MOBA，FPS），可能是 3-5 秒一次；对于慢节奏的游戏，可能是 15-30 秒一次。超时时间也由你定（比如 3 倍心跳间隔）。
- **感知应用状态**：这是它的核心价值。客户端发送的心跳包中可以携带**业务数据**，例如：
    - **客户端时间戳**：用于计算网络延迟（RTT），实现延迟补偿或显示 ping 值。
    - **玩家状态**：如"我在大厅"、"我在战斗中"等，帮助服务器做更精细的管理。
    - **序列号或校验信息**：防止包被篡改。
- **双向对称**：服务器和客户端都可以主动发起和应用层心跳。服务器可以定时检查所有客户端的上次心跳时间，客户端也可以检测服务器是否还"活着"。
- **跨协议通用**：这个设计理念不依赖于 WebSocket。即使你改用 TCP、UDP 甚至其他协议，你的应用层心跳逻辑都可以保持不变。

## 9 MySQL 事务

| 特性                           | 含义                                        | 解释与示例                                                                                                    |
| ---------------------------- | ----------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| **A**tomicity  <br>**原子性**   | 事务是一个不可分割的原子单位，所有操作要么全部成功，要么全部失败。         | 这是事务最核心的特性。靠 **Undo Log** 实现。如果事务中途失败，数据库会利用 Undo Log 将已经执行的操作**完全撤销**，就像这个事务从来没执行过一样。                   |
| **C**onsistency  <br>**一致性** | 事务执行前后，数据库都必须从一个**一致性状态**转变到另一个**一致性状态**。 | 这是事务的**最终目的**。一致性包括预定义的数据规则、约束、触发器等等。例如，转账前后，两个账户的总金额必须保持不变。原子性、隔离性、持久性都是为了保障一致性而存在的手段。                  |
| **I**solation  <br>**隔离性**   | 并发事务之间的操作是相互隔离的，一个事务的执行不应影响其他事务。          | 这是并发控制的核心。数据库通过**锁机制**和 **MVCC** 来实现隔离性。但完全隔离会影响性能，因此提供了不同的**隔离级别**供用户在高性能和高一致性之间做权衡。                    |
| **D**urability  <br>**持久性**  | 一旦事务提交，它对数据库的修改就是永久性的，即使系统发生故障也不会丢失。      | 靠 **Redo Log** 实现。提交事务时，数据变更**可能还没真正写到磁盘的数据文件**中，但一定会先写入 Redo Log。即使数据库宕机，重启后也能根据 Redo Log 重新恢复已提交的事务数据。 |

1. **脏读**：一个事务读到了另一个**未提交事务**修改的数据。
2. **不可重复读**：一个事务内，**两次**读取**同一条**数据，结果不一样（因为另一个**已提交**的事务在中间修改了该数据）。
3. **幻读**：一个事务内，**两次**执行**相同的查询**，返回的**记录数**不一样（因为另一个**已提交**的事务在中间**插入**或**删除**了数据）

| 隔离级别                             | 脏读     | 不可重复读  | 幻读                       | 实现方式简述                                                          |
| -------------------------------- | ------ | ------ | ------------------------ | --------------------------------------------------------------- |
| **读未提交**  <br>(READ UNCOMMITTED) | ❌ 可能发生 | ❌ 可能发生 | ❌ 可能发生                   | 几乎不加锁，性能最高，但问题最多，基本不用。                                          |
| **读已提交**  <br>(READ COMMITTED)   | ✅ 避免   | ❌ 可能发生 | ❌ 可能发生                   | 每个 SELECT 都会生成一个新的**快照**（ReadView），所以总能读到其他事务**已提交**的修改。解决了脏读。  |
| **可重复读**  <br>(REPEATABLE READ)  | ✅ 避免   | ✅ 避免   | ❌ 可能发生  <br>（但 InnoDB 解决了） | **MySQL InnoDB 默认级别**。事务开始时生成一个快照，**整个事务期间**都使用这个快照，因此多次读取结果一致。 |
| **可串行化**  <br>(SERIALIZABLE)     | ✅ 避免   | ✅ 避免   | ✅ 避免                     | 通过强制事务**串行执行**（加锁）来实现最高隔离性。性能最低，一般只在极端场景下使用。                    |

> 隔离级别：**两读两可**。

### 9.1 **非常重要的补充：MySQL InnoDB 对幻读的解决**

在 **可重复读** 隔离级别下，InnoDB 通过 **Next-Key Lock**（临键锁）机制**很大程度上避免了幻读**。Next-Key Lock 是**行锁**（锁定当前行）和**间隙锁**（锁定行之间的范围）的结合。

**例子**： 事务 A 执行 `SELECT * FROM players WHERE level > 50 FOR UPDATE;`（加锁的读）。 InnoDB 不仅会锁住所有 `level > 50` 的**现有行**，还会锁住 `level > 50` 的这个**范围**（间隙）。 这样，事务 B 试图**插入**一个 `level=60` 的新玩家时，就会被阻塞，直到事务 A 提交。这样就避免了幻读。

**注意**：`FOR UPDATE` 这类加锁读会触发 Next-Key Lock，而普通的快照读（不加锁）依靠 MVCC 来保证一致性，理论上在极端并发下仍可能遇到幻读，但概率极低。因此我们通常说 InnoDB 在 RR 级别下**解决了幻读问题**。

### 9.2 MVCC

**MVCC** 的全称是 **Multi-Version Concurrency Control**，中文是**多版本并发控制**。为了避免读写操作互相阻塞，数据库为每一行数据保留多个历史版本（快照）。当一个事务要读取数据时，它会看到在它开始之前就已经提交的数据版本，而不是当前可能正在被其他事务修改的最新版本。

主要依赖三个核心概念：**隐藏的列、Undo log、Read View**

#### 9.2.1 隐藏的列

InnoDB 为每一行数据都自动添加了两个隐藏的字段（其实还有第三个，DB_ROW_ID，这里不讨论）：

- `DB_TRX_ID` (**6 字节**)：**最后修改此行数据的事务 ID**。每当一个事务对某行数据进行**插入（INSERT）** 或**更新（UPDATE）** 操作时，就会将自己的事务 ID 填入这个字段。
- `DB_ROLL_PTR` (**7 字节**)：**回滚指针**。这个指针指向该行数据在 **Undo Log** 中的上一个历史版本。

**每一行数据，通过 `DB_ROLL_PTR` 指针，就形成了一个单向链表，链表的每个节点就是该行数据的一个历史版本。**

#### 9.2.2 Undo Log

- **是什么**：撤销日志，用于事务回滚和 MVCC。
- **作用**：当一行数据被更新时，InnoDB 会先将这行数据的**旧版本**完整地拷贝到 Undo Log 中，然后再修改数据页中的这行数据，同时将新的 `DB_TRX_ID` 和 `DB_ROLL_PTR` 指向刚刚存入 Undo Log 的旧版本记录。
- **版本链**：通过 `DB_ROLL_PTR`，当前数据页中的最新数据可以找到它的上一个版本，上一个版本又可以找到上上个版本，这样就形成了一个**数据版本链**。链表的头部是最新的记录，尾部是最老的记录。

#### 9.2.3 Read View（读视图）

- **是什么**：Read View 是**事务在执行快照读（普通 SELECT）时产生的**，它定义了当前事务能看到哪个版本的数据。
- **关键组成部分**：一个 Read View 主要包含以下几部分：
    - `m_ids`： 生成 Read View 时，系统中**所有活跃（未提交）的事务 ID**列表。
    - `min_trx_id`： `m_ids` 中最小的那个事务 ID。
    - `max_trx_id`： 生成 Read View 时，系统应该分配给**下一个新事务的 ID**。（注意：它并不是 `m_ids` 中的最大值，而是已创建的最大 ID+1）。
    - `creator_trx_id`： 创建这个 Read View 的**当前事务自己的 ID**。

**如果当前版本不可见，就顺着回滚指针 `DB_ROLL_PTR` 找到上一个历史版本，重新执行上述判断规则，直到找到第一个对自己可见的版本为止。**

| 机制                           | 针对的操作类型                                                                                   | 工作原理                                                                                           | 解决的幻读场景                                                                                                 |
| ---------------------------- | ----------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| **MVCC**                     | **快照读**  <br>(Snapshot Read)  <br>例如：`SELECT …`                                           | 通过 **Read View** 和 **Undo Log 版本链**，为事务提供一个**稳定的数据快照**。在这个快照里，第一次查询后，**看不到**其他事务**新插入**并提交的数据。 | 防止事务**看到**幻影行。例如：事务 A 两次 `SELECT`，由于复用同一个 Read View，即使事务 B 插入新行并提交，事务 A 也看不到，从**读取视角**避免了幻读。                    |
| **临键锁**  <br>(Next-Key Lock) | **当前读**  <br>(Current Read)  <br>例如：`SELECT … FOR UPDATE`  <br>`UPDATE …`  <br>`DELETE …` | 通过 **记录锁（行锁） + 间隙锁（Gap Lock）** 的组合，**锁定一个范围**。不仅锁住满足条件的现有记录，还锁住记录之间的"间隙"，防止在这个范围内**插入**新的数据。   | 防止事务**产生**幻影行。例如：事务 A 执行 `SELECT … FOR UPDATE`，临键锁会锁定一个范围。事务 B 试图在这个范围内插入新行时**会被阻塞**，直到事务 A 提交。从**写入视角**避免了幻读。 |

1. **MVCC (解决"看见"的问题)**：它的目标是保证**读一致性**。让读操作（SELECT）不受写操作（UPDATE, INSERT, DELETE）的影响，可以看到一个稳定的视图。它让读操作"看不见"幻影行，但并不阻止其他事务创建幻影行。
2. **临键锁 (解决"产生"的问题)**：它的目标是保证**写操作的独占性**和**数据逻辑的正确性**。当你的当前读操作（比如 `SELECT … FOR UPDATE`）意图基于当前查询结果进行后续更新时，必须确保在本次事务结束前，这个查询结果集不能被其他事务改变（不能插入新的行）。它通过物理上的加锁，直接阻止了幻影行的产生。

## 10 反问

1. 团队气氛
2. 岗位核心能力
3. 岗位 toB/C 依赖的下游，上游
4. 介绍一下部门的核心工作内容
