## 配置 ACR

阿里云的 ACR 容器镜像服务个人版可以免费用，不过使用条件和 dockerhub 有一点点区别，记录一下。大概分为一个命名空间和仓库名。比如我这里：

```go
## 1. 登录阿里云Docker Registry

$ docker login --username=ceyewan registry.cn-hangzhou.aliyuncs.com

用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。

您可以在访问凭证页面修改凭证密码。

## 2. 从Registry中拉取镜像

$ docker pull registry.cn-hangzhou.aliyuncs.com/ceyewan/yingxi-docker:[镜像版本号]

## 3. 将镜像推送到Registry

$ docker login --username=ceyewan registry.cn-hangzhou.aliyuncs.com

请根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。
```

我写了一个这样的脚本，用于打包镜像并推送到仓库上：

```sh
#!/bin/zsh

# 构建 amd64 架构的本地镜像
docker build --platform=linux/amd64 -t hellok8s:v4 .

# 打 tag
docker tag hellok8s:v4 registry.cn-hangzhou.aliyuncs.com/ceyewan/yingxi-docker:hellok8s-v4

# 登录阿里云镜像仓库（如未登录会提示输入用户名密码）
docker login registry.cn-hangzhou.aliyuncs.com

# 推送镜像
docker push registry.cn-hangzhou.aliyuncs.com/ceyewan/yingxi-docker:hellok8s-v4
```

这和普通的不太一样，版本号和镜像名要写到一起，我也不知道为什么，不过这样写了就也还行吧。

## 基础学习

打包得到一个容器镜像，可以将其作为一个 Pod 直接运行，也可以部署为 Deployment 来运行。Deployment 的优势在于，可以自动维护固定的副本数量，比如我们设置是 3，有一个挂了系统会自动创建一个新的。并且也能很好的修改，可以很轻松的修改副本数量、CPU 内存的限制、滚动更新、使用存活探针、就绪探针来获取 Pod 的状态。也支持版本回退之类的。

Service 可以为多个 Pod 集群提供一个稳定的 Endpoint，Service 位于 pod 的前面，负责接收请求并将它们传递给它后面的所有 pod。这样外部就不用管内部 Pod 的状态了。

在 Kubernetes 中，`Service` 是一种抽象，用于定义一组 Pod 的访问策略和方式。Kubernetes 提供了几种不同类型的 `Service`，以满足不同的网络访问需求。最常见的三种类型是：

- **ClusterIP**：为服务分配一个内部 IP（仅集群内可访问），使得服务只能在集群内部访问。适用于仅在集群内部通信的服务，例如后端微服务之间的调用。
- **NodePort**：在所有节点上开放一个特定端口（NodePort），通过该端口可以从外部访问服务。外部访问地址为 `<任意节点IP>:<NodePort>`，注意是节点 IP 而不是 Pod IP 了，随便用那个物理节点的 IP，会负载均衡到所有 Pod 上。
- **LoadBalancer**：在支持的云平台上自动创建外部负载均衡器，并将流量转发到服务。基于 NodePort 或 ClusterIP 实现，但在云环境中会自动配置外部负载均衡器，适用于生产环境，需要高可用、稳定外网访问的场景。

**Ingress** 是 Kubernetes 中用于管理**外部 HTTP/HTTPS 流量** 进入集群的 API 对象。它提供了一种**统一、灵活的方式** 来暴露多个服务（Service），并支持基于路径、域名等进行路由。我们部署了很多 Pod，相同服务的 Pod 使用 Service 提供一个统一的入口。假设我有两个不同的服务，那么就有两个入口，不管二者分别是多少个 Pod。然后 Ingress 提供了路由功能，这样同一个域名，不同的 URL 被定向到不同的入口，请求不同的服务。

ACK 提供自研的 ALB Ingress Controller，他依赖 ALBConfig，需要配置至少两个虚拟交换机和对应的外部弹性 IP。我没搞明白创建集群之后的配置方式，所以只能在创建集群时，通过界面点击，配置好 ALBConfig。

下面就是一个 Ingress 的配置，我的想法是使用我的域名来访问，然后配置 cname 域名解析到阿里云的 Endpoint，不过文档说是还要配置一下 txt 解析，不知道怎么配，就没管了。

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hello-ingress
spec:
  ingressClassName: alb
  rules:
    - host: hello.ceyewan.icu
      http:
        paths:
          - path: /hello
            pathType: Prefix
            backend:
              service:
                name: service-hellok8s-clusterip
                port:
                  number: 3000
          - path: /
            pathType: Prefix
            backend:
              service:
                name: service-nginx-clusterip
                port:
                  number: 4000
```

k8s 也支持命令空间，将同一集群中的资源划分为相互隔离的组。 同一名字空间内的资源名称要唯一，但跨名字空间时没有这个要求。 名字空间作用域仅针对带有名字空间的对象，例如 Deployment、Service 等。默认就是 **default** 空间。

ConfigMap 用于将配置数据和应用程序代码分开，对于要从环境变量中获取的数据，我们可以提前存储到 ConfigMap 中。

Secret 用于存储 ConfigMap 中不能存储的密钥信息等，这部分内容需要安全存储。

除了服务性任务，还有一种任务是一次性任务，即 Job，只需要拿到相关数据计算后得出结果即可，无需一直运行。对于 Job，会创建多个 Pod 来执行，只到有达到阈值的成功执行后，任务结束。

**Helm 是 Kubernetes 的包管理工具** ，可以理解为 Kubernetes 的 "apt"。
- **Chart**：Helm 包，里面是一组描述 Kubernetes 应用的 YAML 模板文件。
- **Release**：使用 Chart 安装后的一个运行实例。你可以多次安装同一个 Chart，得到多个 Release。
- **Repository**：存放 Chart 的仓库，类似于 Linux 的软件源。

创建一个 Helm Chart，将自己的 yaml 配置写到 Chart 里面去，最后 `helm install my-release ./my-app` 就可以部署应用了。参数分别是这个部署的名字和 chart 的路径。优势在于支持版本号、历史记录、回滚等操作；统一打包为 Chart 便于分发和复用；社区提供了大量的 Chart 可供直接使用。

## 弹性伸缩

首先是 Pod 的 HPA 和 VPA，HPA 是水平扩缩容，根据负载情况（如 CPU 使用率、内存使用率或自定义指标），**动态调整某个 Deployment 或 ReplicaSet 中的 Pod 数量** 。

```sh
kubectl autoscale deployment my-deployment --cpu-percent=50 --min=2 --max=10
```

 比如上面的命令就创建了一个弹性扩缩容的 deployment，基于 CPU 阈值为 50% 进行扩容，Pod 的最大最小值。适用于当应用的请求量波动较大时，比如电商秒杀、流量高峰等。

VPA 是垂直扩缩容机制，**VPA 的作用是根据实际资源使用情况，自动调整 Pod 的 CPU 和内存的请求值（resources.requests）** 。它不是增加或减少 Pod 数量（那是 HPA 干的事），而是 " 给每个 Pod 分配更合适的资源 "。

此外，ACK 还提供**节点自动扩缩容（Cluster AutoScaler, CA）**，当集群中的节点资源不足时，**自动增加或减少节点数量** 。这里关注的是 Node 层面，而不是上面的 Pod 层面。比如我们一个 Pod 要求 2 核 2 G，现在我们要 10 个 Pod，Node 的资源不够了，就会触发 CA。比较适合长期资源需求变化。

- 如果只有 HPA，当所有节点资源耗尽时无法继续扩容；
- 如果只有 CA，不能根据应用负载精细调整资源，容易造成浪费。
