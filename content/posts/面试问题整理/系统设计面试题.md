---
date: 2025-09-21 14:13:48+08:00
draft: true
slug: 20250921-tvw7rz2k
summary: 本文详解游戏排行榜、高并发系统、流式计算与分布式任务调度设计，涵盖Redis分片、缓存优化、MapReduce处理及Gang调度等核心技术方案。
tags:
  - System-Design
categories:
  - Interview
---

## 1 解题框架

系统设计面试的核心是评估工程师在面对复杂、模糊问题时，能否运用工程思维，设计出合理、可扩展且可靠的系统。其目的并非要求一个完美无缺的方案，而是考察候选人的结构化思维、技术视野、权衡能力和沟通效率。

### 1.1 破题 (Scoping) - 场景与需求分析

这是设计的起点。任何不明确需求的设计都是空中楼阁。候选人需要主动与面试官沟通，将一个模糊的问题转化为清晰、可量化的目标。

- **功能性需求 (Functional Requirements)**：明确系统必须具备的核心功能。
    - 示例：对于一个短视频平台，核心功能包括：用户上传视频、浏览推荐 Feed 流、点赞、评论。
- **非功能性需求 (Non-Functional Requirements)**：定义系统的质量属性和性能指标，这是后续架构选型的关键依据。
    - **规模与负载 (Scale & Load)**：预估系统的用户量级，如百万级日活跃用户 (DAU)，以及核心操作的每秒查询率 (QPS) 或吞吐量。
    - **延迟 (Latency)**：定义关键操作的响应时间要求。例如，用户刷新 Feed 流的 P99 延迟需在 200ms 以内。
    - **可用性 (Availability)**：系统需要达到的正常运行时间百分比。例如，99.99% 的可用性意味着每年只有约 52 分钟的停机时间。
    - **一致性 (Consistency)**：明确分布式环境下数据的同步要求。是要求强一致性（如支付场景），还是可以接受最终一致性（如用户点赞数）。
- **约束与边界 (Constraints & Boundaries)**：明确设计中需要考虑的限制，如技术栈、成本预算、开发时间等，并明确哪些功能不在本次设计的考虑范围内。

### 1.2 蓝图 (High-Level Design) - 高层架构设计

在明确需求后，搭建系统的整体骨架，并向面试官清晰地展示你的设计思路。

- **核心组件与服务划分 (Component & Service Breakdown)**：将系统拆分为若干个高内聚、低耦合的核心服务。例如，一个电商系统可以拆分为用户服务、商品服务、订单服务和支付服务。绘制简洁的架构图是此阶段沟通的关键。
- **接口定义 (API Design)**：定义关键组件或服务之间的通信协议和核心接口。例如，使用 RESTful API 或 gRPC，并明确核心端点，如 `POST /api/v1/tasks` 和 `GET /api/v1/tasks/{taskId}`。
- **技术选型与论证 (Technology Choices & Justification)**：为关键组件选择合适的技术栈，并给出充分的理由。这里的核心是展示你对不同技术优劣势及其适用场景的理解。
    - 示例：为何选择 Kafka 而不是 RabbitMQ？可能是因为业务场景更侧重高吞 - 吐量和数据回溯能力，而非复杂的消息路由。为何使用 Redis 而不是 Memcached？可能是因为需要利用 Redis 丰富的数据结构，如 Sorted Sets。

### 1.3 攻坚 (Deep Dive) - 深入细节设计

选择 1-2 个最核心或最具挑战性的模块进行深入剖析，展示你的技术深度。

- **数据模型设计 (Data Modeling)**：设计数据库的表结构 (Schema) 或 NoSQL 的文档结构。考虑数据分片 (Sharding) 和索引策略。
- **核心流程与算法 (Core Logic & Algorithms)**：详细阐述关键业务逻辑的实现。例如，Feed 流的推荐算法、抢红包的资金分配算法、分布式 ID 生成器的具体实现等。
- **关键挑战与解决方案 (Key Challenges & Solutions)**：识别并解决设计中的经典难题。
    - **高并发 (High Concurrency)**：如何应对海量请求？常见的策略包括缓存（多级缓存）、负载均衡、消息队列异步处理、限流与熔断。
    - **高可用 (High Availability)**：如何避免单点故障 (SPOF)？通过冗余设计，如主从复制、多活数据中心、故障转移 (Failover) 机制来保证。
    - **数据一致性 (Data Consistency)**：在分布式系统中，如何保证数据正确性？根据业务需求选择合适的策略，如两阶段提交 (2PC)、TCC、Saga 模式或基于消息队列的最终一致性方案。

### 1.4 收尾 (Wrap-up) - 优化与迭代

在完成核心设计后，主动展现对系统全局的思考和未来的规划。

- **瓶颈分析 (Bottleneck Analysis)**：主动识别当前设计中可能存在的性能瓶颈（例如，数据库热点、单点写入的组件），并说明其潜在影响。
- **可扩展性设计 (Scalability Plan)**：针对已识别的瓶颈，提出具体的水平扩展 (Horizontal Scaling) 或垂直扩展 (Vertical Scaling) 方案。
- **运维与监控 (Operations & Monitoring)**：简要说明需要监控哪些核心指标来保障系统健康。例如：系统层面的 CPU/内存/网络，应用层面的 QPS、延迟、错误率，以及业务层面的关键指标（如订单量、在线用户数）。

## 2 设计游戏排行榜

### 2.1 明确需求

1. **功能性需求**:
    - **分数提交/更新**: 玩家上传游戏分数。同一玩家的新分数会覆盖旧分数。
    - **Top-K 查询**: 获取排名最高的 K 位玩家列表（例如 Top 100）。
    - **个人排名查询**: 查询指定玩家的当前分数、排名，以及其相邻的 M 位玩家（例如前后各 5 名）。
2. **非功能性需求**:
    - **用户规模**: 预估总用户量为 1 亿，日活跃用户 (DAU) 为 1000 万。
    - **写入负载**: 假设 DAU 平均每人每天产生 10 次分数更新，则总写入次数为 1000 万 * 10 = 1 亿次/天。
        - 写入 QPS: 1 亿 / (24 * 3600) ≈ 1157 QPS。考虑到流量高峰，峰值 QPS 可能达到 3-5 倍，约 3500 - 6000 QPS。
        - 写入延迟: 写入操作对用户是后台行为，可接受秒级延迟，不要求强实时性。
    - **读取负载**: 排行榜的读取操作非常频繁，预估读 QPS 是写的 10 倍以上，峰值可达 10k - 20k QPS。
    - **读取延迟**: 读取操作直接面向用户，要求低延迟，P99 响应时间应在 100ms 以内。
    - **可用性**: 排行榜是游戏的核心功能，需要保证高可用性 (e.g., 99.95%)。
    - **一致性**: 用户可以容忍自己排名的秒级延迟，因此采用最终一致性是可接受的。

**核心挑战**: 在亿级用户数据规模下，实现一个高并发、低延迟、高可用的实时排名系统。

### 2.2 架构设计

**架构图描述:**  

客户端请求 -> API 网关 -> 排行榜服务。  
对于写请求：排行榜服务 -> 消息队列 -> 消费者服务 -> Redis 集群。  
对于读请求：排行榜服务 -> Redis 集群 (优先读从节点) -> 客户端。

- **API 网关 (API Gateway)**: 作为系统的统一流量入口，负责请求路由、身份验证、速率限制 (Rate Limiting) 等。
- **排行榜服务 (Leaderboard Service)**: 核心业务逻辑层，封装了排行榜的读写 API。
- **消息队列 (Message Queue, e.g., Kafka)**: 用于解耦和削峰填谷。将高并发的写入请求异步化，将瞬时写入压力平摊到后端消费者，极大地提高了系统的写入吞吐量和稳定性。
- **数据存储 (Data Store, e.g., Redis Cluster)**: 存储排行榜数据的核心组件。

**核心流程**:

- **写入流程 (异步)**:
    - 客户端通过 API 网关调用排行榜服务的 updateScore 接口。
    - 排行榜服务进行基本校验后，将包含 userId 和 score 的消息发送到 Kafka。
    - 独立的消费者服务从 Kafka 拉取消息，并将其写入 Redis。
    - **权衡 (Trade-off)**: 采用异步写入，牺牲了分数的绝对实时性（引入了消息队列的延迟），但换取了系统的高吞吐量和弹性，避免了数据库写入瓶颈直接影响用户请求。
- **读取流程 (同步)**:
    - 客户端通过 API 网关调用排行榜服务的 getTopK 或 getRank 接口。
    - 排行榜服务直接查询 Redis Cluster。
    - 将从 Redis 获取的数据格式化后返回给客户端。此路径必须经过高度优化以满足低延迟要求。

### 2.3 细节设计

**数据模型：为何选择 Redis Sorted Set?**

在需要对海量数据进行实时排序和范围查询的场景下，传统关系型数据库（如 MySQL）的 ORDER BY 操作在数据量巨大时会产生严重的性能问题，通常涉及文件排序，无法满足低延迟要求。

Redis 的有序集合 (Sorted Set) 是为此类场景设计的理想数据结构。

- **内部实现**: Sorted Set 内部通过**跳表 (Skip List)** 和**哈希表 (Hash Table)** 两种数据结构组合实现。
    - **跳表**: 保证了元素按分数有序，使得范围查询（如 Top-K）和排名查询的时间复杂度为 **O(log N + M)**，其中 N 是集合大小，M 是返回的元素数量。
    - **哈希表**: 存储了成员 (member) 到分数 (score) 的映射，使得更新或获取单个成员分数的时间复杂度为 **O(1)**。
- **核心操作映射**:
    - **插入/更新分数**: `ZADD leaderboard:global <score> <userId>`。该命令同时处理插入和更新，时间复杂度为 O(log N)。
    - **查询 Top-K (降序)**: `ZREVRANGE leaderboard:global 0 <K-1> WITHSCORES`。时间复杂度为 O(log N + K)。
    - **查询用户排名 (降序)**: `ZREVRANK leaderboard:global <userId>`。时间复杂度为 O(log N)。
    - **查询用户分数**: `ZSCORE leaderboard:global <userId>`。时间复杂度为 O(1)。
    - **查询用户及其周边排名**: 这需要组合多个命令。先用 ZREVRANK 找到用户排名 R，再用 ZREVRANGE 查询 R-M 到 R+M 范围的玩家。

**可用性与扩展性设计**

- **高可用性**:
    - 采用 **Redis 主从复制 (Primary-Replica)** 架构。写操作在主节点，读操作可以在所有从节点进行，分担读取压力。
    - 配合 **Redis Sentinel (哨兵) 或 Redis Cluster 自带的故障转移机制**，实现对主节点的健康监控和自动故障转移，确保服务在主节点宕机时能够快速恢复。
- **数据分片 (Sharding)**:
    - **按榜单分片**: 如果存在多个维度的排行榜（如赛季榜、区服榜、好友榜），最自然的策略是按排行榜 ID 进行分片。例如，`leaderboard:S3_EU` 和 `leaderboard:S3_NA` 可以哈希到不同的 Redis 实例上。
    - **全局总榜的挑战与方案**: 对于一个需要容纳所有用户的巨大全局榜，单个 Sorted Set 可能会耗尽单机内存。此时无法简单地按 userId 分片，因为所有用户必须在同一个集合内才能比较。解决方案如下：
        - **分层思想**: 将用户分散到多个分片 (Shard) 中，例如 100 个分片。每个分片都是一个独立的 Sorted Set。
        - **Top-K 查询**: 从每个分片中取出 Top-K（例如 K=100），然后在服务层对这 100 * 100 个结果进行内存排序，得到最终的全局 Top 100。
        - **个人排名查询**: 用户的排名变为 (其所在分片的前面所有分片的用户总数) + (其在分片内的排名)。这需要额外的元数据来维护每个分片的用户数，且排名是近似的。对于绝大多数用户，这是一个可接受的方案。

### 2.4 优化方向

- **多级缓存策略**:
    - 对于变化不那么频繁的 Top-K 榜单（如 Top 100），可以在**排行榜服务**内部增加一个本地缓存 (In-memory Cache, e.g., Caffeine/Guava Cache)，或者使用一个独立的分布式缓存（如 Memcached）。
    - 该缓存每隔一个短周期（如 5 秒）从 Redis 拉取最新数据，这样可以拦截绝大部分对 Top-K 的查询，极大降低对 Redis 的直接压力。
- **数据持久化与冷备**:
    - 开启 Redis 的 **AOF (Append-Only File)** 持久化，以保证数据在实例重启后的可恢复性，同时兼顾性能。
    - 对于历史排行榜数据（如上个赛季的榜单），应从 Redis 中归档到更廉价的持久化存储中（如 MySQL 或对象存储），以释放昂贵的内存资源。
- **监控与告警**:
    - **Redis 指标**: 监控 CPU 使用率、内存占用、命令延迟、命中率。
    - **消息队列指标**: 监控消息积压 (Lag) 数量，确保消费者消费能力跟得上生产者。
    - **应用指标**: 监控 API 的 QPS、P99 延迟和错误率。
    - 设置关键告警，如消息队列积压超过阈值、Redis 主从延迟过大等。

## 3 设计一个高并发系统

设计一个高并发系统，特别是像 **购票系统** 这样的场景，涉及大量的并发请求、高性能处理以及数据一致性保证。我们可以从 **宏观（整体架构层面）** 和 **微观（细节优化层面）** 两个方向来考虑如何应对高并发。

### 3.1 宏观设计：整体架构层面

在宏观层面，主要考虑 **系统的可扩展性**、**高可用性**、**负载均衡** 和 **缓存设计** 等方面。

#### 3.1.1 分布式架构与微服务

- **微服务架构**：将购票系统拆分为多个微服务，每个微服务专注于特定的功能模块，如用户服务、票务服务、支付服务等。这样可以做到横向扩展，支持高并发。
- **服务拆分**：购票系统的不同功能可以拆分为多个服务，避免单点压力集中。例如，用户验证服务、票务查询服务、支付服务、订单管理服务等，彼此解耦，支持独立扩展。

#### 3.1.2 负载均衡与高可用性

- **DNS 负载均衡**：通过 **DNS** 将请求分配到多个可用区域，利用 DNS 解析的方式进行简单的流量分配。
- **负载均衡**：通过 **负载均衡器**（如 Nginx 或 LVS）将流量均匀分配到多个后端服务器或微服务实例中，避免单个节点的瓶颈。
- **高可用性**：采用 **主从复制** 和 **自动故障转移机制**（如使用 **Redis Sentinel** 或 **Kubernetes** 的健康检查与自动重启）来确保系统的高可用。

#### 3.1.3 缓存设计

缓存是高并发系统中优化性能和减少延迟的关键技术。

- **热点数据缓存**：使用 **Redis** 或 **Memcached** 缓存常用的查询结果，例如已售票数量、剩余票数等。
    - **分布式缓存**：通过 Redis 集群或分布式缓存来保证缓存的高可用性，防止单点故障。
    - **缓存穿透、缓存雪崩和缓存击穿问题**：通过合理的 **缓存过期时间** 和 **双重检查锁** 来解决这些问题。
    - **本地缓存**：针对一些高频访问的数据，可以使用本地缓存（如 **Go** 中的 **map** 或 **LRU 缓存**）来减少外部请求。

#### 3.1.4 异步处理与消息队列

- **消息队列**：使用 **Kafka**、**RabbitMQ** 等消息队列来解耦系统内部的各个模块，特别是涉及高并发的操作，比如 **订单确认** 和 **支付处理**。消息队列可以作为缓冲区，避免瞬时请求对系统造成过大的冲击。
- **异步处理**：对于一些非实时的操作（如发送短信通知、生成订单日志等），可以采用异步任务处理，减轻主流程的压力。

#### 3.1.5 静态资源缓存与 CDN

- **CDN（内容分发网络）**：将静态资源（如 **首页图片**、**广告**、**API 请求的结果**）通过 **CDN** 缓存到离用户最近的节点，减少从源服务器的请求压力。对于购票系统，这可以显著减轻来自静态资源（如票务列表、广告等）的访问压力。
    - **缓存静态内容**：如购票系统的静态页面、公告、促销信息等，可以通过 CDN 缓存来大幅减少数据库和后台服务的访问量。
    - **API 数据缓存**：例如对于频繁查询的热门票务数据、热门场次等，可以通过 CDN 和边缘节点的缓存来处理，减少中心服务器的压力。

### 3.2 微观设计：细节优化层面

在微观层面，考虑 **单个请求的高效处理** 和 **资源利用的最大化**。

#### 3.2.1 零拷贝技术

- **零拷贝（Zero-Copy）**：通过操作系统的零拷贝机制减少数据在内存中的复制，提高网络传输效率。比如，使用 **sendfile** 系统调用将数据直接从文件系统传输到网络连接中，避免了不必要的数据拷贝。
- **数据库读写优化**：通过 **数据库连接池** 和 **零拷贝技术**，减少数据库查询的延迟和资源占用，保证高并发情况下数据库的吞吐量。

#### 3.2.2 高效的数据库设计

- **数据库分片**：对数据库进行分片，根据不同的策略（如 **用户 ID**、**订单号**、**地理区域**）将数据分布到不同的数据库节点，避免单个数据库的负载过重。
- **读写分离**：通过 **主从复制** 实现读写分离，读操作可以通过从库进行，减轻主库的压力。
- **乐观锁与悲观锁**：通过 **乐观锁** 和 **事务隔离** 来保证数据一致性，避免因并发操作引发的数据冲突，确保购票操作的准确性。
- **合并请求（批处理）**：对于大量的并发请求，可以通过 **批处理** 和 **合并操作** 来减少数据库的访问次数，例如批量更新票务库存等。

#### 3.2.3 限流与熔断机制

- **限流**：在高并发场景下，可以使用 **令牌桶** 或 **漏桶算法** 来进行限流，控制请求的频率，防止系统过载。
- **熔断机制**：使用 **Hystrix** 或 **Sentinel** 等熔断框架，当系统的某个模块出现异常时，能够自动切换到降级策略，保护系统不被单一故障影响。

#### 3.2.4 连接池与资源复用

- **数据库连接池**：使用 **连接池** 来管理数据库连接，减少频繁创建和销毁连接带来的性能开销。
- **线程池与协程**：使用 **线程池** 或 **协程池**（如 **Go** 中的协程）来管理和复用工作线程，减少频繁创建和销毁线程的开销，提高并发处理能力。

#### 3.2.5 高效的网络 I/O

- **异步 I/O**：通过 **非阻塞 I/O** 和 **事件驱动模型**（如使用 **epoll**）来处理大量的并发连接，避免因为 I/O 操作阻塞导致的性能瓶颈。
- **HTTP/2 或 gRPC**：在 API 通信中使用 **HTTP/2** 或 **gRPC**，它们可以更高效地处理大量并发请求，支持多路复用，减少网络延迟。

## 4 设计一个流式计算系统

### 4.1 需求分析

- **功能性需求**:
    - **广告投放 (Ad Serving)**: 当用户访问 App 或网站时，系统需要快速选择并返回一个合适的广告。**（注意：广告的"选择"逻辑，即竞价、排序、用户画像匹配等，本身是一个极其复杂的系统。在本次设计中，我们将其抽象为一个"广告决策服务"，重点关注其下游的数据流处理。）**
    - **事件跟踪 (Event Tracking)**: 必须实时捕获两种核心事件：
        - **广告曝光/展示 (Impression)**: 广告被成功加载并展示给用户。
        - **广告点击 (Click)**: 用户点击了展示的广告。
    - **数据处理与聚合**: 系统需要近实时地统计关键指标，例如：每个广告、每个广告活动的曝光量、点击量和点击率 (CTR)。
    - **报告生成 (Reporting)**:
        - **实时仪表盘**: 为广告主提供一个可以看到分钟级更新数据的实时 Dashboard。
        - **离线分析报告**: 提供更复杂、更精确的 T+1 小时/天级别的深度分析报告，用于结算和优化。
- **非功能性需求 (量化)**:
    - **高吞吐量**: "全网"意味着巨大的流量。
        - **曝光事件**: 假设峰值 QPS 为 **100 万/秒**。
        - **点击事件**: 假设平均 CTR 为 1%，峰值 QPS 为 **1 万/秒**。
    - **低延迟**:
        - **广告投放**: 必须极快，P99 延迟 < 50ms。
        - **事件跟踪**: 数据上报路径可以容忍秒级延迟。
        - **实时报告**: 数据反映到仪表盘的延迟应在 1-5 分钟内。
    - **高可用性**: 整个系统，尤其是数据收集和处理链路，必须 7x24 小时可用。
    - **数据准确性**: 报告数据，尤其是用于计费的离线报告，必须准确无误。这意味着需要处理数据乱序、重复等问题，并追求"恰好一次" (Exactly-once) 的处理语义。

**核心挑战**: 构建一个能够处理百万级 QPS 事件流、支持实时与离线两种分析场景、并保证数据准确性的高可用数据管道。

### 4.2 高层架构设计

我们将系统划分为几个逻辑层：数据采集层、数据流处理层、数据存储层和数据应用层。面对百万 QPS，单台机器肯定无法处理，所以我们的核心思想是**分而治之 (Divide and Conquer)**。我们需要将海量的数据流打散，让成百上千台机器并行处理，最后再将结果汇总。

- **数据采集层**:
    - **客户端 (App/Web)**: 产生数据源。
    - **日志网关 (Gateway)**: 这是一个高可用的 HTTP 服务集群，前面用 Nginx 或 LVS 做负载均衡。它的职责非常单一：接收请求，然后立刻把日志数据扔进下游的"缓冲池"里，快速响应客户端。
- **数据缓冲层 (Buffer)**:
    - **消息队列 (Kafka)**: 为什么需要它？
        - **削峰填谷**: 前端流量有高峰有低谷（潮汐效应），但我们希望后端的处理系统能够平稳工作。Kafka 就像一个巨大的水库，无论前端来多大的洪水，它都能先接下来，后端处理系统再按照自己的节奏匀速消费。
        - **解耦和可靠性**: 如果没有 Kafka，日志网关直接调用处理服务，一旦处理服务宕机，数据就丢失了。有了 Kafka，即使后端处理服务全挂了，数据也暂存在 Kafka 里，等服务恢复后可以继续处理，保证了数据不丢失。
- **数据处理层**:
    - **实时计算集群**: 这是我们设计的核心。它是一个由很多普通服务器组成的集群，从 Kafka 读取数据进行计算。我们稍后会深入设计它。
- **数据存储与应用层**:
    - **实时存储 (Redis/MySQL)**: 用于存放分钟级的统计结果，给实时仪表盘查询。
    - **离线存储 (HDFS/S3)**: 存放所有最原始的日志文件，用于后续更精确的批量计算。可以把它理解为一个超大的分布式硬盘。
    - **报表服务**: 一个普通的后端 Web 服务，从 Redis/MySQL 读取数据提供实时 API，从离线仓库读取数据提供离线 API。

### 4.3 深入设计：从零构建

#### 4.3.1 **核心问题一：如何将曝光和点击关联起来？**

为了计算 CTR，我们必须知道哪次点击对应哪次曝光。这就需要"关联"(Join)。

- **数据设计**: 在广告曝光时，生成一个全局唯一的 impressionId。当用户点击时，客户端必须把这个 impressionId 也一起上报。
- **处理逻辑**:
    - **数据分发 (Partitioning)**: 我们不能随机把数据丢给集群中的机器处理。必须保证**同一个 impressionId 的曝光和点击事件，被发送到同一台机器上**。这怎么做到？我们可以用一个简单的一致性哈希算法：machine_index = hash(impressionId) % machine_count。Kafka 的生产者在发送消息时，可以指定一个 Key (impressionId)，Kafka 会自动帮我们完成这个分发过程。
    - **状态化处理 (Stateful Processing)**: 既然相关的事件都到了一台机器上，这台机器就需要"记住"一些信息。这就是"状态"。
        - 当这台机器收到一个**曝光事件**时，它不能立即丢弃，因为可能几分钟后才会有对应的点击事件到来。它需要把这个曝光事件存入一个**内存中的哈希表 (HashMap)** 里，key 是 impressionId，value 是曝光的详细信息。
        - 当收到一个**点击事件**时，它就去这个哈希表里查找 impressionId。
            - **找到了**: 关联成功！生成一个"关联后"的事件，然后可以从哈希表中删除这个 impressionId 的记录了。
            - **没找到**: 可能是曝光事件因为网络延迟还没到，或者这是一个无效点击。

#### 4.3.2 **核心问题二：内存会无限增长怎么办？**

如果只存不删，机器的内存迟早会爆掉（因为很多曝光永远不会有点击）。

- **解决方案：超时清理 (TTL)**: 我们需要为存在内存哈希表里的曝光事件设置一个"过期时间"。比如，一个曝光事件如果在内存里待了超过 1 小时还没有等到点击，我们就认为它永远等不到了，直接将它从哈希表中删除。这可以通过一个后台的定时清理任务来完成。

#### 4.3.3 **核心问题三：如何进行统计聚合？**

我们不能每来一个事件就去更新数据库，那样会把数据库写爆。

- **解决方案：微批处理/窗口聚合 (Micro-batch / Windowing)**:
    - 每台处理机在自己的内存里维护一组计数器，例如一个哈希表：Map<adId, impressionCount> 和 Map<adId, clickCount>。
    - 它会累积处理一段时间的数据（比如 1 分钟）。
    - 每隔 1 分钟，它就把自己内存里这批聚合好的结果（不是一条条的明细！）一次性写入到外部的实时存储（如 Redis）中。
    - 例如，机器 A 在 12:01:00 到 12:01:59 之间，处理了广告 ad-123 的 1000 次曝光和 10 次点击。在 12:02:00 时，它会向 Redis 执行 HINCRBY ad_stats:12:02 ad-123_impressions 1000 和 HINCRBY ad_stats:12:02 ad-123_clicks 10。
    - 这样，数据库的写入压力大大降低了。

#### 4.3.4 **核心问题四：机器挂了怎么办？(容错)**

如果一台处理机突然宕机，它内存里正在处理的数据（状态和计数器）就全丢了，这会导致数据不准。

- **解决方案：定期快照 (Checkpointing)**:
    - 这是一个相对简化的容错思路。每台处理机可以**定期地**（比如每 5 分钟）把它内存中的哈希表（就是那个存着未等到点击的曝光事件的表）和当前的计数器，完整地**序列化并写入到一个可靠的外部存储**（比如 HDFS 或 S3）中。
    - 同时，它也需要记录下自己从 Kafka 消费到了哪个位置（Offset）。
    - 当这台机器挂掉后，一个新的机器可以启动，从外部存储中加载最近一次的快照来恢复内存状态，然后告诉 Kafka 从上次记录的位置继续消费数据。这样虽然会丢失一部分数据（从上次快照到宕机之间的数据），但已经是一个基本的容错方案了。

我们上面讨论的这些核心问题——**数据分区、状态管理、窗口聚合、容错机制**——其实是所有大数据流计算系统都需要解决的通用问题。而像 **Apache Flink** 这样的专业框架，就是把这些问题做了非常完善和高效的封装。它提供了开箱即用的状态管理、精确一次的容错保证（通过更高级的分布式快照算法）和丰富的窗口 API，让开发者可以更专注于业务逻辑，而不用从头造这些复杂的轮子。所以，在实际工程中，我们会选择 Flink 这样的框架来搭建这个系统。

## 5 设计一个分布式任务调度系统

### 5.1 需求与挑战

- **核心功能**:
    - **任务提交**: 用户通过异步 API 提交推理任务，任务包含所需 GPU 类型、数量、显存等资源规格。
    - **任务调度**: 系统根据用户优先级、资源可用性和调度策略，将任务分配到合适的 GPU 节点上执行。
    - **状态管理**: 用户可查询任务状态（排队中、运行中、已完成、失败）。
- **核心挑战与约束**:
    - **服务质量 (QoS) 分层**: VIP 用户的任务在排队和资源分配上享有高优先级。
    - **公平性保障**: 必须避免普通用户任务因连续的 VIP 任务而"饿死" (Starvation)。
    - **资源利用率最大化 (超卖)**: 调度器需智能地"填补"GPU 资源空隙，减少闲置，尤其是在潮汐效应的低谷期。
    - **组调度 (Gang Scheduling)**: 必须保证需要多个 GPU 的任务，其所需资源被"同时"分配，这是一个原子性要求。
    - **非抢占式长任务**: 任务一旦开始，将长时间占用资源且不可中断。这使得调度决策的"反悔"成本极高，必须在调度时就做出明智选择。

### 5.2 高层架构设计

我们将系统拆分为几个核心服务，它们协同工作来完成任务的生命周期管理。

**流程:** 用户请求 -> API 层 -> 任务服务 -> [元数据 DB, 任务队列] -> 调度中心 -> [元数据 DB, 资源监控] -> GPU 节点代理 -> GPU 节点

- **API 层 (API Layer)**: 统一入口，负责接收用户的任务提交和状态查询请求，并进行鉴权。
- **任务服务 (Task Service)**: 负责处理任务的业务逻辑。当接收到新任务时，它会：
    - 校验任务参数的合法性。
    - 将任务的详细信息（taskId, userId, userType, resourceRequest, status='QUEUED'）存入**元数据数据库**。
    - 将 taskId 推入一个或多个**任务队列**中。
- **元数据数据库 (Metadata DB, e.g., PostgreSQL/MySQL)**: 存储系统的核心状态信息。
    - **任务表 (Tasks)**: 记录每个任务的属性、状态和生命周期。
    - **GPU 节点表 (Nodes)**: 记录集群中所有 GPU 节点的静态信息（ID, GPU 型号, 总显存）和动态状态（空闲、占用中、维护中）。
- **任务队列 (Task Queues, e.g., Redis List/ZSET)**: 这是调度系统的"待办事项"列表。为了实现 VIP 优先，我们不使用单一队列。
    - **设计选择**: 采用**多个优先级队列**。例如，一个 vip_queue 和一个 normal_queue。调度器会优先从 vip_queue 中拉取任务。
- **调度中心 (Scheduler Service)**: **系统的"大脑"**，也是设计的核心。它是一个独立的、持续运行的服务，其主要职责是：
    - **监控资源**: 持续从 GPU 节点或资源监控服务（如 Prometheus）收集实时的资源使用情况。
    - **触发调度**: 定期或在事件驱动下（如新任务到达、任务完成）运行调度算法。
    - **决策与分发**: 运行调度算法，匹配任务与资源，并将决策下发给相应的 GPU 节点。
- **GPU 节点 (GPU Worker Node)**: 实际执行计算的机器。
    - 每个节点上运行一个**代理 (Agent)**，负责与调度中心通信，汇报心跳和自身状态，并接收指令来启动/停止任务容器。

### 5.3 深入设计 - 调度中心

调度中心的每一次运行都可以看作一个"调度周期"，其核心逻辑如下：

#### 5.3.1 数据模型

- **任务 (Task)**: `{taskId, userId, userType, status, requiredGpuType, requiredGpuCount, requiredMemory, submitTime}`
- **节点 (Node)**: `{nodeId, gpuType, totalGpuCount, availableGpuCount, totalMemory, availableMemory, status}`

#### 5.3.2 核心调度算法

调度算法的目标是在满足所有约束的前提下，找到最优的 `(Task, [Node1, Node2, …])` 匹配。

**步骤 1: 任务选择 (Task Selection) - 融合优先级与公平性**

调度器不会无限制地只看 VIP 队列。它会采用一种**带配额的优先级策略**。

- **配额系统**: 定义一个时间窗口（例如 1 小时），并规定在此窗口内，分配给 VIP 和普通用户的 GPU 小时数比例不应超过某个阈值（例如 80:20）。
- **选择逻辑**:
    - 检查当前时间窗口内，VIP 用户的资源消耗是否已超出配额。
    - 如果**未超出**，则从 vip_queue 的队头取一个任务进行尝试调度。
    - 如果**已超出**，或 vip_queue 为空，则从 normal_queue 的队头取一个任务。
- **饥饿避免**: 为了防止队头的普通任务因资源不满足而长期阻塞，可以引入**任务老化 (Aging)** 机制。任务在队列中等待的时间越长，其内部优先级就越高，当高到一定程度时，调度器会更积极地为它寻找资源。

**步骤 2: 资源过滤 (Filtering) - 寻找候选节点**

对于选定的任务，调度器需要在集群中筛选出所有**可能**满足其需求的 GPU 节点。

- **过滤条件**:
    - node.status == 'HEALTHY'
    - node.gpuType == task.requiredGpuType
    - node.availableGpuCount > 0
    - node.availableMemory >= task.requiredMemory (如果是单 GPU 任务)

对于**组调度**任务（requiredGpuCount > 1），此步骤会更复杂，需要找到一个**节点组合**，其 availableGpuCount 之和大于等于 task.requiredGpuCount。

**步骤 3: 资源打分 (Scoring) - 做出最优选择**

经过滤后，可能会有多个节点或节点组合满足条件。此时需要一个打分函数来选出"最佳"的一个。这是实现**资源利用率最大化**的关键。

- **打分策略 (Bin Packing)**:
    - **最差拟合 (Worst-Fit)**: 优先选择剩余资源**最多**的节点。
        - **优点**: 这种策略倾向于将小任务分散部署，从而为未来的大型（多 GPU）任务保留出连续的、未被占用的"大块"节点。**对于需要组调度的场景，这通常是更优的选择。**
    - **最佳拟合 (Best-Fit)**: 优先选择剩余资源**最少**但又能满足任务需求的节点。
        - **优点**: 这种策略倾向于将节点"填满"，让其他节点完全空闲，便于在业务低谷时将这些空闲节点缩容以节省成本。
- **决策**: 调度器会计算每个候选节点/节点组的分数，选择分数最高的进行分配。

**步骤 4: 绑定与下发 (Binding & Dispatching)**

一旦做出决策，调度器需要原子性地完成绑定操作。

- 在**元数据数据库**中，将任务状态更新为 RUNNING，并记录其绑定的节点 ID。
- 同时更新对应节点的 availableGpuCount 和 availableMemory。
- 向目标节点的 Agent 发送启动任务的指令。
    - **容错**: 如果指令下发失败，或 Agent 启动任务失败，需要执行**回滚**操作：将任务状态重置为 QUEUED 并放回队列头部，同时恢复节点的资源信息。这个过程需要事务性或重试机制来保证状态一致性。

#### 5.3.3 利用历史数据与潮汐效应

- **预测性调度**: 既然可以获取历史数据，调度器可以内置一个简单的预测模型。
    - **预测任务时长**: 根据相似任务（相同模型、相似输入大小）的历史执行时间，预估当前任务的运行时长。
    - **预测负载高峰**: 预测接下来的几个小时是否为业务高峰。
- **智能决策 - 回填调度 (Backfilling)**: 这是高级调度器提升利用率的利器。
    - **场景**: 队列头部是一个需要 8 个 GPU 的大任务，但当前只有 6 个 GPU 空闲。按照普通逻辑，这 6 个 GPU 只能闲置，等待其他任务释放资源。
    - **回填逻辑**: 调度器会向后扫描队列，寻找那些**体量小、预计运行时长短**的任务（例如一个只需要 1 个 GPU、预计运行 10 分钟的小任务）。如果调度器预测，运行这个小任务**不会影响**那个大任务的预计启动时间（即在这 10 分钟内，所需的另外 2 个 GPU 还不会被释放），那么它就会"插队"运行这个小任务，从而把 GPU 的闲置时间利用起来。

### 5.4 总结与权衡

该设计方案的核心是一个**状态驱动、带配额优先级、并采用过滤 - 打分模型的调度中心**。

- **权衡 1 (公平性 vs 优先级)**: 我们没有采用绝对的 VIP 优先，而是通过**配额系统**在两者之间取得了平衡，保证了平台的长期健康，避免了普通用户的流失。
- **权衡 2 (实现复杂度 vs 调度效率)**: 引入了**回填调度**和**预测模型**，这增加了调度器的实现复杂度，但能显著提升 GPU 资源利用率和系统吞吐量，对于成本敏感的 GPU 售卖业务是值得的。
- **权衡 3 (数据一致性)**: 调度器是系统的核心状态决策者，其对元数据数据库的读写一致性要求很高。在调度周期的关键步骤（如资源预留和绑定）可能需要使用**数据库事务或乐观锁**来避免因并发调度而导致资源被超额分配。

## 6 TODO

### 6.1 大型社交与内容平台

1. **设计一个类似 Twitter / X 的信息流（Feed）系统：** 要求能实时更新，并支持关注/被关注关系，如何处理"扇出"（fan-out）？
2. **设计一个 Instagram 风格的图片分享服务：** 如何高效地存储和分发大量的图片和视频？如何设计其时间线？
3. **设计一个 YouTube 或 Netflix 平台：** 重点考虑视频的上传、转码、存储和流畅播放（CDN 设计）。
4. **设计一个 Reddit 或 Hacker News 这样的论坛系统：** 如何设计帖子、评论的嵌套结构以及投票排序算法？

### 6.2 实时与通信系统

5. **设计一个即时通讯（IM）系统，如 WhatsApp 或 Facebook Messenger：** 如何保证消息的实时性、可靠性和顺序性？如何处理在线/离线状态？
6. **设计一个类似 Uber 或 Lyft 的网约车应用：** 如何实时匹配司机和乘客，并持续追踪位置？
7. **设计一个实时协作的在线文档工具，如 Google Docs：** 如何处理多人同时编辑的冲突问题（CRDTs 或 OT）？
8. **设计一个推送通知系统（Push Notification System）：** 如何将通知高效、低延迟地推送给海量用户？

### 6.3 电商与金融系统

9. **设计一个电商网站的秒杀系统：** 如何应对瞬时高并发流量，保证系统的稳定性和数据一致性（库存不能超卖）？
10. **设计一个类似亚马逊的电商网站：** 重点设计其商品详情页、购物车和订单处理流程。
11. **设计一个点评系统，如 Yelp 或大众点评：** 如何存储和索引大量的地理位置信息（Geo-indexing），并支持附近商家的快速搜索？
12. **设计一个抢票系统，如 Ticketmaster 或 12306：** 如何处理高并发下的座位锁定和支付流程？

### 6.4 数据密集型与基础设施

13. **设计一个 URL 短链接服务，如 TinyURL 或 bit.ly：** 如何生成唯一的短 URL，并处理高并发的重定向请求？
14. **设计一个网络爬虫（Web Crawler）：** 如何高效地抓取网页，处理重复内容，并遵守 `robots.txt` 协议？
15. **设计一个高可用的分布式键值存储系统（Key-Value Store），如 Redis 或 DynamoDB：** 如何实现数据的分区、复制和故障转移？
16. **设计一个分布式 ID 生成器（Unique ID Generator）：** 在分布式环境下，如何生成全局唯一且趋势递增的 ID？

### 6.5 其他常见系统

18. **设计一个网站的速率限制器（Rate Limiter）：** 如何有效地防止 API 被滥用，支持多种限流算法（如令牌桶、漏桶）？
19. **设计一个分布式日志系统：** 如何收集、聚合和查询海量服务器产生的日志？
20. **设计一个搜索自动补全（Typeahead/Autocomplete）系统：** 当用户输入时，如何快速返回相关的搜索建议？
