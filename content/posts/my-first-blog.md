+++
date = '2025-06-25T22:12:45+08:00'
draft = false
title = 'Model Context Protocol Crash Course'
categories = ["AI Agent"]
tags = ["MCP", "Agent"]
+++


## 1 引言

在 AI 领域，尤其是大语言模型（LLM）应用中，**如何让模型灵活获取外部实时信息、调用工具、集成多源数据**，一直是开发者面临的核心难题。  
MCP（Model Context Protocol，模型上下文协议）正是为了解决这一痛点而诞生的，它就像 AI 世界的 "USB-C"，统一了 AI 与外部能力（工具、资源等）之间的连接标准。

![image.png](https://ceyewan.oss-cn-beijing.aliyuncs.com/typora/20250621105636.png)

### 1.1 LLM 的局限与需求

- LLM 的知识固化在训练数据中，无法主动获取实时信息。
- 传统 prompt 工程、RAG 检索、手动集成工具等方式各有不足，难以满足复杂、动态需求。
- 需要一个**标准化、可扩展、易集成的协议**，让模型能像调用 USB 设备一样调用外部能力。

---

## 2 LLMs 的上下文管理

### 2.1 传统方法

- **截断/滑动窗口**：保留最近对话，丢弃旧信息，易丢失重要上下文。
- **摘要法**：对长内容做摘要，易丢失细节且需要额外计算。
- **模板化 prompt**：预留插槽（slots）手动填充信息，开发负担大。

### 2.2 RAG（检索增强生成）

- 外部系统负责检索，模型被动接收，无法主动发起信息获取。
- 主要解决知识查找，但不支持 " 调用工具 " 类操作。

### 2.3 Prompt 链与 Agent

- 利用模型输出特殊指令（如 `SEARCH: xxx`）由外部系统解析执行。
- 实现了初步的 " 推理 + 行动 "（ReAct），但缺乏标准，集成脆弱，难以复用。

### 2.4 函数调用 Function Calling

- 结构化定义可调用函数，模型输出 JSON 指令，由外部执行并反馈结果。
- 结构化程度提升，但仍需为每对模型与工具定制 glue code，维护困难。

### 2.5 M×N 集成难题

- N 个工具 × M 个 AI 应用，需开发 N×M 套集成代码，极其低效。
- 工具与模型间缺乏统一标准，导致 " 集成地狱 "，迫切需要一套标准协议。

---

## 3 MCP：模型上下文协议

### 3.1 MCP 是什么？

- **定义**：MCP 是一种开放的、标准化的协议，规范了 AI 应用与外部工具/资源的交互方式。
- **作用**：像 USB-C 一样，MCP 让任何 AI 应用与任何 MCP 能力（工具/资源/提示词）都能即插即用、互操作。
- **意义**：
  - 开发者只需实现一次 MCP 客户端/服务器，即可集成所有能力，极大降低开发和维护成本。
  - 工具/资源提供方只需实现一次 MCP 服务端，即可服务所有支持 MCP 的 AI 应用。
  - 用户获得更强大、更灵活、更实时的 AI 助手体验。

![image.png](https://ceyewan.oss-cn-beijing.aliyuncs.com/typora/20250621111133.png)

### 3.2 MCP 的优势

- **动态能力发现**：AI 可实时查询服务器支持哪些工具/资源，灵活适配新能力。
- **有状态交互**：基于 Host 支持会话式、多轮、多工具协作，具备上下文记忆。
- **多步编排与智能决策**：AI 可自主编排工具调用，实现复杂任务自动化。
- **安全与人控**：敏感操作可统一加权限校验，防止误操作。
- **解耦与可扩展性**：AI 应用与工具资源完全解耦，生态开放、易于扩展。

---

## 4 MCP 架构详解

### 4.1 三大核心角色

| 角色   | 定位         | 主要职责                   | 举例                      |
|------|------------|-------------------------|------------------------|
| Host | 用户侧应用      | 管理用户输入输出、会话状态、决定何时调用外部能力 | Claude Desktop、Cursor、定制 AI 助手等 |
| Client | Host 内部组件 | 具体负责与 MCP Server 按协议通信，转发请求与响应 | SDK、适配层              |
| Server | 能力提供方    | 暴露工具/资源/提示词，按协议响应调用请求      | 本地/远程工具服务器、API 封装等     |

#### 4.1.1 Host

- 用户交互入口，负责整体流程编排和上下文管理。
- 依赖 LLM 决定何时、用什么参数调用哪台 MCP Server。
- 例：Claude Desktop、AI 编辑器等。

#### 4.1.2 Client

- 具体负责协议通信、请求转发、错误处理等。
- 每连一台 MCP Server，就有一个 Client 实例。
- 类比：浏览器的网络层。

#### 4.1.3 Server

- 按标准暴露工具/资源/提示词，响应客户端请求。
- 可本地运行，也可远程部署。
- 例：数据库服务器、API 封装服务、文件操作服务等。

### 4.2 通信流程

1. **用户发起请求**（如 " 查下旧金山天气 "）
2. **Host 建立连接**，Host 的 MCP Client 与 MCP Server 建立连接
3. **能力发现**：Client 查询 Server 支持的工具/资源
4. **Host 解析需求**，依赖 LLM 基于请求和能力决定需调用天气工具
5. **Client 建立连接**到天气 MCP Server
6. **工具调用**：Client 发送调用请求（如 `get_weather`）
7. **Server 执行并返回结果**
8. **结果整合**：Client 将结果交给 Host，Host 再提供给模型
9. **多轮交互/多工具编排**（如需）
10. **连接关闭**（如会话结束）

> **优势**：只需新建/注册新的 MCP Server，Host 即可自动发现和使用，无需改动主应用代码！

---

## 5 MCP 能力体系（Capabilities）

MCP Server 可以向 Client 暴露多种能力，分为四大类：

### 5.1 Tools（工具/操作）

- **定义**：可执行的函数或动作，通常具备副作用（如调用外部 API）。
- **触发方式**：由 LLM（经 Host）自主决定何时调用。
- **安全性**：常需用户许可（如发送邮件、执行代码等高风险操作）。
- **开发示例**：Python 函数通过 `@mcp.tool()` 注册，如天气查询、计算、货币转换等。

### 5.2 Resources（资源）

- **定义**：只读数据源，供 AI 查询信息（无副作用，仅检索）。
- **访问控制**：通常由 Host 控制何时访问，避免模型随意读取敏感数据。
- **场景举例**：公司手册、知识库、数据库查询、本地文件等。

### 5.3 Prompts（提示词/模板）

- **定义**：预定义的提示模板或对话流程，帮助引导 AI 行为。
- **使用方式**：多用于初始化对话场景或设定系统角色，由用户/开发者选择。
- **优势**：可随服务端更新，无需修改客户端代码，便于复用和管理。

### 5.4 Sampling（采样）

- **定义**：服务端请求 AI 执行 LLM 操作的机制，支持更复杂的多步推理、自反思等高级能力。

---

## 6 MCP 通信协议详解

### 6.1 基础协议：JSON-RPC 2.0

- **优点**：轻量、跨语言、易读，广泛支持。
- **消息类型**：
    - **Request**：客户端发起调用（如 tools/call、tools/list），带唯一 `id`、`method`、`params`。
    - **Response**：服务端响应（带同一 `id`），返回 `result` 或 `error`。
    - **Notification**：服务器单向通知客户端，无需响应（如进度更新、异步事件）。

### 6.2 传输方式

- **Stdio（标准输入输出）**：适合本地子进程插件，简单高效。
- **HTTP + SSE（Server-Sent Events）**：适合远程/长连接服务，支持流式消息与进度推送。

---

## 7 MCP 交互生命周期

1. **Initialization（初始化阶段）**
    - 客户端发送 `initialize` 请求，协商协议版本、身份、偏好等。
    - 服务端确认后，客户端发送 `initialized` 通知，双方准备就绪。
2. **Discovery（能力发现阶段）**
    - 客户端依次请求 `tools/list`、`resources/list`、`prompts/list` 等，获取所有可用能力及参数描述，供 LLM/Host 决策调用。
3. **Execution（执行阶段）**
    - 客户端根据用户意图和能力清单，发起具体调用（如 `tools/call`、`resources/read`）。
    - 服务端执行并返回结果，同时可通过 Notification 推送进度、事件等异步信息。
4. **Termination（终止阶段）**
    - 会话结束时，客户端发送 `shutdown` 请求，服务端确认后可发送 `exit` 通知，安全关闭连接和资源。

## 8 FC vs. MCP

|方面|传统函数调用（FC）|模型上下文协议（MCP）|
|---|---|---|
|**集成方式**|手动、强耦合、特定应用内|标准协议、解耦、跨平台复用|
|**扩展性**|新增/变更功能需多处手动维护|动态能力发现，自动同步，无需手动改代码|
|**维护成本**|代码重复、易出错、升级难|集中更新，所有客户端自动获知新能力|
|**灵活性**|刚性，难以适配不同工具/模型|灵活，支持多模型多工具自由组合|
|**安全合规**|各自实现，难统一审计审批|协议内置审批、日志、权限管理|
|**典型使用场景**|小型项目、单一模型对接少量工具|企业级、多模型、多工具/数据源场景|

其实功能上差不多，只不过 MCP 抽象出了一个中间层，标准化了一个协议解决了 FC 存在的问题，**没有什么是加一个中间层不能解决的**。

## 9 MCP 客户端和服务端实现

我们可以动手编程实现一个 MCP 客户端和服务器，在客户端的实现过程中，不同的模型可能支持的模型调用方法并不一样，例如 gpt-4o 就可以在一次响应时发起对两个 MCP Tools 的调用，而 qwen-plus-latest 只支持一次调用一个 Tool，两个 Tool 就需要迭代循环两轮。

![image.png](https://ceyewan.oss-cn-beijing.aliyuncs.com/typora/20250621150033.png)

## 10 MCP Resources

### 10.1 概念与直觉

- 资源并不是数据本身，而是**访问数据的只读接口**，如文件内容、API 缓存响应、数据库快照、文档片段等。
- 资源的本质是**知识库**，供模型查阅而不产生任何副作用。

>⚠️ 资源的内容如果发生变更，需重新加载，模型上下文才会感知到变化。

### 10.2 资源类型

- **文本资源**：如源码文件、配置文件、日志、JSON/XML、纯文本等。
- **二进制资源**：如图片、PDF、音视频等，通常以 base64 编码。

### 10.3 资源发现与管理

- **直接资源**：通过 `/resources/list` 接口暴露，适合静态、已知资源。
- **资源模板**：如 `file://{path}`，基于 RFC 6570 标准，实现动态资源发现，适合大规模、动态内容。

### 10.4 访问控制

- **应用控制**：资源的获取由客户端显式发起，LLM 不能主动请求，增强了安全性和可预测性。例如 Claude Desktop 要求用户手动选择资源。

### 10.5 资源注册与元数据

- 通过装饰器注册静态或动态资源，并可自定义名称、描述、MIME 类型、大小等元数据。
- 支持重复注册的行为控制（警告、报错、替换、忽略）。

## 11 MCP Prompts

### 11.1 概念与直觉

- 提示是由服务器暴露的**可复用消息模板**，用于结构化地引导 LLM 的角色、推理流程或多轮对话。
- 典型用途包括：代码解释、文档摘要、法律审查、标准化输出格式等。

### 11.2 为什么要有提示？

- **统一与复用**：用户无需重复编写复杂 prompt，服务器端统一管理与更新，便于维护和扩展。
- **可发现性**：客户端可通过 `/prompts/list` 发现所有可用提示。
- **参数化与验证**：支持类型注解、自动参数校验、生成 schema。

### 11.3 FastMCP 中的实现

- 使用 `@mcp.prompt` 装饰器定义，支持单条消息、多轮对话、类型注解、元数据自定义（如名称、描述、标签）。
- 支持禁用、重复注册处理等高级特性。
